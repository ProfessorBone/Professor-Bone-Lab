{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30989026",
   "metadata": {},
   "source": [
    "<a id=\"section-1\"></a>\n",
    "# Section 1: What Is Reasoning in Agentic Systems?\n",
    "\n",
    "Before we can build reasoning into agents, we must understand what \"reasoning\" actually means in this context.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 What Is Reasoning?\n",
    "\n",
    "**Reasoning is the process by which an agent decides what to do next based on:**\n",
    "1. What it knows (state)\n",
    "2. What it needs to know (goals)\n",
    "3. What it can do (capabilities/tools)\n",
    "4. What it has learned (observations)\n",
    "\n",
    "### In Everyday Terms\n",
    "\n",
    "Imagine you're planning a trip:\n",
    "\n",
    "```\n",
    "Thought: \"I need to get to the airport\"\n",
    "   â†“\n",
    "Reasoning: \"Should I drive or take a train?\"\n",
    "   â†“\n",
    "Decision: \"Train is faster during rush hour\"\n",
    "   â†“\n",
    "Action: Check train schedule\n",
    "   â†“\n",
    "Observation: Next train in 30 minutes\n",
    "   â†“\n",
    "Reasoning: \"30 minutes is enough time to get to station\"\n",
    "   â†“\n",
    "Decision: Book train ticket\n",
    "```\n",
    "\n",
    "This is **stepwise reasoning** â€” not a single prompt, but a chain of decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.2 How Reasoning Differs from Text Generation\n",
    "\n",
    "| Aspect | Text Generation | Agent Reasoning |\n",
    "|--------|----------------|------------------|\n",
    "| **Input** | Prompt + context | State + goal + observations |\n",
    "| **Process** | Single LLM call | Multiple steps with decisions |\n",
    "| **Output** | Text response | Decision + action + new state |\n",
    "| **Feedback** | None (one-shot) | Iterative (observe â†’ decide â†’ act) |\n",
    "| **Memory** | Context window only | Persistent state across steps |\n",
    "| **Debuggability** | Hard (black box) | Easy (trace each step) |\n",
    "\n",
    "### Example: Text Generation\n",
    "\n",
    "```\n",
    "Prompt: \"Summarize this article about transformers\"\n",
    "   â†“\n",
    "[LLM generates summary]\n",
    "   â†“\n",
    "Done.\n",
    "```\n",
    "\n",
    "**One step. No reasoning trace. No intermediate decisions.**\n",
    "\n",
    "### Example: Agent Reasoning\n",
    "\n",
    "```\n",
    "Goal: \"Summarize recent research on transformers\"\n",
    "   â†“\n",
    "Reasoning: \"I need to find recent papers\"\n",
    "   â†“\n",
    "Action: Search academic database\n",
    "   â†“\n",
    "Observation: Found 10 papers\n",
    "   â†“\n",
    "Reasoning: \"Which papers are most relevant?\"\n",
    "   â†“\n",
    "Action: Rank by citation count and date\n",
    "   â†“\n",
    "Observation: Top 3 papers identified\n",
    "   â†“\n",
    "Reasoning: \"Should I read abstracts or full text?\"\n",
    "   â†“\n",
    "Action: Read abstracts\n",
    "   â†“\n",
    "Observation: Key findings extracted\n",
    "   â†“\n",
    "Reasoning: \"Now I can synthesize\"\n",
    "   â†“\n",
    "Action: Generate summary\n",
    "   â†“\n",
    "Done.\n",
    "```\n",
    "\n",
    "**Multiple steps. Each step has explicit reasoning. Decisions are observable.**\n",
    "\n",
    "---\n",
    "\n",
    "## 1.3 Why Reasoning Must Be Externalized\n",
    "\n",
    "LLMs can \"think\" internally (chain-of-thought), but for agents, **internal reasoning is insufficient**.\n",
    "\n",
    "### The Problem with Internal Reasoning\n",
    "\n",
    "```python\n",
    "# What the LLM sees:\n",
    "prompt = \"\"\"\n",
    "You are a helpful agent. Think step by step.\n",
    "\n",
    "Task: Find papers on transformers and summarize.\n",
    "\"\"\"\n",
    "\n",
    "# LLM internal monologue (hidden):\n",
    "# \"First I'll search... then I'll read... then I'll summarize...\"\n",
    "# â†“\n",
    "# [Generates text that LOOKS like it did those steps]\n",
    "# â†“\n",
    "response = \"Based on recent papers, transformers use attention...\"\n",
    "```\n",
    "\n",
    "**Problems:**\n",
    "1. âŒ Did the agent actually search? **Unknown.**\n",
    "2. âŒ Which papers did it find? **Unknown.**\n",
    "3. âŒ Why did it choose those papers? **Unknown.**\n",
    "4. âŒ Can we verify the summary? **No.**\n",
    "5. âŒ Can we debug if it's wrong? **No.**\n",
    "\n",
    "### The Solution: Externalized Reasoning\n",
    "\n",
    "```python\n",
    "# Agent explicitly records its reasoning:\n",
    "state = {\n",
    "    \"thought\": \"I need to search for papers\",\n",
    "    \"action\": \"search_database\",\n",
    "    \"action_input\": {\"query\": \"transformers 2024\"},\n",
    "    \"observation\": \"Found 10 papers\",\n",
    "    \"next_thought\": \"I should rank by relevance\",\n",
    "    # ... and so on\n",
    "}\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "1. âœ… Every decision is recorded\n",
    "2. âœ… Every action is traceable\n",
    "3. âœ… Observations are logged\n",
    "4. âœ… We can debug each step\n",
    "5. âœ… We can validate correctness\n",
    "\n",
    "---\n",
    "\n",
    "## 1.4 Implicit vs Explicit Reasoning\n",
    "\n",
    "### Implicit Reasoning (Hidden)\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Prompt with instructions   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â”‚\n",
    "               â–¼\n",
    "       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "       â”‚     LLM      â”‚  â† Reasoning happens here (invisible)\n",
    "       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "              â”‚\n",
    "              â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚  Text Response   â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Characteristics:**\n",
    "- Reasoning is internal to the LLM\n",
    "- No intermediate steps visible\n",
    "- Cannot inspect or validate\n",
    "- Looks like magic\n",
    "\n",
    "### Explicit Reasoning (Externalized)\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Goal/Task  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n",
    "       â”‚\n",
    "       â–¼\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”‚  Thought: ...   â”‚  â† Recorded in state\n",
    "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚\n",
    "           â–¼\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”‚  Action: ...    â”‚  â† Recorded in state\n",
    "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚\n",
    "           â–¼\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”‚ Observation: ...â”‚  â† Recorded in state\n",
    "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚\n",
    "           â–¼\n",
    "     [Repeat until done]\n",
    "```\n",
    "\n",
    "**Characteristics:**\n",
    "- Reasoning is externalized to state\n",
    "- Each step is observable\n",
    "- Can inspect and validate\n",
    "- Transparent and debuggable\n",
    "\n",
    "---\n",
    "\n",
    "## 1.5 Key Insight: Reasoning â‰  Chain-of-Thought\n",
    "\n",
    "Many tutorials show \"chain-of-thought\" prompting:\n",
    "\n",
    "```\n",
    "Prompt: \"Think step-by-step: What is 15% of 80?\"\n",
    "Response: \"Let me think:\n",
    "1. 10% of 80 is 8\n",
    "2. 5% is half of that, so 4\n",
    "3. 15% = 10% + 5% = 8 + 4 = 12\"\n",
    "```\n",
    "\n",
    "This is **internal reasoning made visible**, but:\n",
    "- It's still in the LLM's response (not structured)\n",
    "- Cannot be validated programmatically\n",
    "- Cannot branch based on intermediate results\n",
    "- Cannot call tools between steps\n",
    "\n",
    "**Agent reasoning is different:**\n",
    "- Structured (fields in state)\n",
    "- Actionable (can call tools)\n",
    "- Iterative (observe â†’ reason â†’ act)\n",
    "- Observable (every step is logged)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Key Takeaway: Section 1\n",
    "\n",
    "> **Agent reasoning is the externalized, structured, iterative process by which an agent decides what to do next. Unlike text generation or chain-of-thought, agent reasoning produces observable decision traces that can be validated, debugged, and audited.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7c635",
   "metadata": {},
   "source": [
    "<a id=\"section-2\"></a>\n",
    "# Section 2: Stateless Reasoning vs Structured Reasoning\n",
    "\n",
    "Let's explore the spectrum from simple prompting to structured reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 One-Shot Prompting (No Reasoning)\n",
    "\n",
    "The simplest form: ask a question, get an answer.\n",
    "\n",
    "### Conceptual Flow\n",
    "\n",
    "```\n",
    "User Question\n",
    "     â†“\n",
    "  [LLM]\n",
    "     â†“\n",
    "  Answer\n",
    "```\n",
    "\n",
    "### Characteristics\n",
    "\n",
    "- **No intermediate steps**: Question â†’ Answer directly\n",
    "- **No memory**: Each question is independent\n",
    "- **No reasoning trace**: We don't know how the LLM arrived at the answer\n",
    "- **No tool use**: Cannot search, calculate, or take actions\n",
    "\n",
    "### When This Works\n",
    "\n",
    "âœ… Simple factual questions  \n",
    "âœ… Well-scoped tasks within context  \n",
    "âœ… No need for verification  \n",
    "\n",
    "### When This Fails\n",
    "\n",
    "âŒ Multi-step problems  \n",
    "âŒ Needs external information  \n",
    "âŒ Requires verification  \n",
    "âŒ Must be auditable  \n",
    "\n",
    "---\n",
    "\n",
    "## 2.2 Hidden Chain-of-Thought\n",
    "\n",
    "We prompt the LLM to \"think step-by-step\" but the reasoning stays in the response text.\n",
    "\n",
    "### Conceptual Flow\n",
    "\n",
    "```\n",
    "User Question + \"Think step-by-step\"\n",
    "     â†“\n",
    "  [LLM]\n",
    "     â†“\n",
    "  Response with reasoning text:\n",
    "  \"Step 1: ...\n",
    "   Step 2: ...\n",
    "   Therefore: ...\"\n",
    "```\n",
    "\n",
    "### Characteristics\n",
    "\n",
    "- **Reasoning is visible**: We can read the steps\n",
    "- **But it's unstructured**: Reasoning is in natural language text\n",
    "- **Cannot branch**: Can't take different actions based on intermediate steps\n",
    "- **Cannot validate**: Can't programmatically check if reasoning is sound\n",
    "- **No tool use**: Still just text generation\n",
    "\n",
    "### Example\n",
    "\n",
    "```\n",
    "Prompt: \"Calculate the total cost of 3 items at $15.99 each with 8% tax. Think step-by-step.\"\n",
    "\n",
    "Response:\n",
    "\"Let me work through this:\n",
    "Step 1: Cost of 3 items = 3 Ã— $15.99 = $47.97\n",
    "Step 2: Tax = $47.97 Ã— 0.08 = $3.84\n",
    "Step 3: Total = $47.97 + $3.84 = $51.81\n",
    "\n",
    "The total cost is $51.81.\"\n",
    "```\n",
    "\n",
    "### The Problem\n",
    "\n",
    "This looks like reasoning, but:\n",
    "1. The math might be wrong (we can't verify programmatically)\n",
    "2. We can't extract intermediate values for further processing\n",
    "3. We can't branch (e.g., \"if tax > $5, apply discount\")\n",
    "4. The reasoning exists only in text, not in state\n",
    "\n",
    "---\n",
    "\n",
    "## 2.3 Why Hidden Reasoning Breaks Debuggability\n",
    "\n",
    "### Scenario: Research Agent\n",
    "\n",
    "Imagine an agent that should:\n",
    "1. Search for papers\n",
    "2. Filter by relevance\n",
    "3. Summarize findings\n",
    "\n",
    "#### Hidden Reasoning Approach\n",
    "\n",
    "```\n",
    "Prompt: \"\"\"\n",
    "You are a research agent. Find recent papers on transformers and summarize.\n",
    "Think step-by-step.\n",
    "\"\"\"\n",
    "\n",
    "Response:\n",
    "\"Step 1: I would search for papers on transformers from 2024\n",
    "Step 2: I would filter for high-impact papers\n",
    "Step 3: Based on my knowledge, here's a summary:\n",
    "Transformers have evolved to...\"\n",
    "```\n",
    "\n",
    "**Problems:**\n",
    "\n",
    "| Question | Answer with Hidden Reasoning |\n",
    "|----------|------------------------------|\n",
    "| Did the agent actually search? | Unknown (it claims to, but didn't) |\n",
    "| Which papers were found? | None (it hallucinated) |\n",
    "| How were they filtered? | Unknown (no actual filtering occurred) |\n",
    "| Is the summary accurate? | Cannot verify (no source papers) |\n",
    "| Can we debug if wrong? | No (no intermediate data) |\n",
    "\n",
    "---\n",
    "\n",
    "## 2.4 Why Reasoning Artifacts Belong in State, Not Prompts\n",
    "\n",
    "### What Are Reasoning Artifacts?\n",
    "\n",
    "Reasoning artifacts are the **outputs of reasoning steps**:\n",
    "\n",
    "- The thought/decision made\n",
    "- The action chosen\n",
    "- The observation received\n",
    "- Intermediate conclusions\n",
    "- Why a particular path was taken\n",
    "\n",
    "### Why They Belong in State\n",
    "\n",
    "| If in Prompts (Bad) | If in State (Good) |\n",
    "|---------------------|--------------------|\n",
    "| Invisible to code | Accessible to code |\n",
    "| Cannot be validated | Can be validated |\n",
    "| Cannot be logged separately | Can be logged separately |\n",
    "| Hard to debug | Easy to debug |\n",
    "| Lost after response | Preserved across steps |\n",
    "| Unstructured text | Structured data |\n",
    "\n",
    "### Example: State-Based Reasoning\n",
    "\n",
    "```python\n",
    "# Conceptual structure (no executable code yet)\n",
    "reasoning_state = {\n",
    "    \"step\": 1,\n",
    "    \"thought\": \"I need to search for papers\",\n",
    "    \"action\": \"search\",\n",
    "    \"action_input\": {\"query\": \"transformers 2024\"},\n",
    "    \"observation\": \"Found 10 papers: [...]\",\n",
    "    \"reasoning_trace\": [\n",
    "        \"Step 1: Search identified\",\n",
    "        \"Step 2: Papers retrieved\",\n",
    "        # ...\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Now:\n",
    "- âœ… We know exactly what action was taken\n",
    "- âœ… We have the actual search results\n",
    "- âœ… We can validate the observation\n",
    "- âœ… We can debug if something goes wrong\n",
    "- âœ… The reasoning is structured and queryable\n",
    "\n",
    "---\n",
    "\n",
    "## 2.5 The Spectrum of Reasoning Approaches\n",
    "\n",
    "```\n",
    "LEAST STRUCTURED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º MOST STRUCTURED\n",
    "\n",
    "One-Shot          Chain of         Hidden ReAct        Explicit\n",
    "Prompting         Thought          (in text)          Reasoning\n",
    "                                                      (in state)\n",
    "   â”‚                 â”‚                 â”‚                  â”‚\n",
    "   â”‚                 â”‚                 â”‚                  â”‚\n",
    "   â–¼                 â–¼                 â–¼                  â–¼\n",
    "\n",
    "No trace       Text trace      Text-based         Structured\n",
    "No steps       Visible steps   steps              state fields\n",
    "Not           Not              Not fully          Fully\n",
    "debuggable    validatable      externalized       observable\n",
    "```\n",
    "\n",
    "**We want to be on the right side of this spectrum for production agents.**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Key Takeaway: Section 2\n",
    "\n",
    "> **Hidden reasoning (chain-of-thought in prompts) is insufficient for agents. Reasoning must be externalized into structured state where each thought, action, and observation is a first-class field that can be validated, logged, and debugged.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df8578",
   "metadata": {},
   "source": [
    "<a id=\"section-3\"></a>\n",
    "# Section 3: Reasoning as a Process, Not a Prompt\n",
    "\n",
    "The fundamental shift: reasoning is not what you write in a promptâ€”it's the **process** the agent executes.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 Reasoning as Stepwise Decision-Making\n",
    "\n",
    "True agent reasoning is a **loop**, not a single call.\n",
    "\n",
    "### The Basic Loop\n",
    "\n",
    "```\n",
    "1. Look at current state\n",
    "   â†“\n",
    "2. Decide what to do next (reasoning)\n",
    "   â†“\n",
    "3. Take an action\n",
    "   â†“\n",
    "4. Observe the result\n",
    "   â†“\n",
    "5. Update state\n",
    "   â†“\n",
    "[Repeat until goal achieved]\n",
    "```\n",
    "\n",
    "### Concrete Example\n",
    "\n",
    "**Goal**: Book a flight to Paris\n",
    "\n",
    "```\n",
    "State: {goal: \"Book flight to Paris\", current_step: null}\n",
    "   â†“\n",
    "Reasoning: \"I need to know the dates first\"\n",
    "   â†“\n",
    "Action: Ask user for dates\n",
    "   â†“\n",
    "Observation: User says \"Dec 15-22\"\n",
    "   â†“\n",
    "State Update: {dates: \"Dec 15-22\", current_step: \"dates_obtained\"}\n",
    "   â†“\n",
    "Reasoning: \"Now I should search for flights\"\n",
    "   â†“\n",
    "Action: Search flights\n",
    "   â†“\n",
    "Observation: Found 5 flights\n",
    "   â†“\n",
    "State Update: {flights: [...], current_step: \"flights_found\"}\n",
    "   â†“\n",
    "Reasoning: \"I should present options to user\"\n",
    "   â†“\n",
    "...\n",
    "```\n",
    "\n",
    "Notice:\n",
    "- **Each reasoning step** looks at the current state\n",
    "- **Each action** modifies the world (or gathers information)\n",
    "- **Each observation** provides new information\n",
    "- **State grows** with each iteration\n",
    "\n",
    "---\n",
    "\n",
    "## 3.2 Thought â†’ Action â†’ Observation (The ReAct Pattern)\n",
    "\n",
    "This pattern is called **ReAct** (Reasoning + Acting).\n",
    "\n",
    "### The Core Loop\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                                     â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚\n",
    "â”‚   â”‚  THOUGHT  â”‚  \"What should I do?\" â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                    â”‚\n",
    "â”‚         â”‚                           â”‚\n",
    "â”‚         â–¼                           â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚\n",
    "â”‚   â”‚  ACTION   â”‚  \"Do this\"          â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                    â”‚\n",
    "â”‚         â”‚                           â”‚\n",
    "â”‚         â–¼                           â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚\n",
    "â”‚   â”‚OBSERVATION â”‚  \"I learned...\"    â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                   â”‚\n",
    "â”‚         â”‚                           â”‚\n",
    "â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚\n",
    "â”‚                      â”‚              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                       â”‚\n",
    "                  [Repeat]\n",
    "```\n",
    "\n",
    "### What Each Component Means\n",
    "\n",
    "#### THOUGHT (Reasoning)\n",
    "- \"What do I know?\"\n",
    "- \"What do I need to know?\"\n",
    "- \"What action should I take?\"\n",
    "- \"Am I done?\"\n",
    "\n",
    "**Stored in state as:** `current_thought` or `reasoning`\n",
    "\n",
    "#### ACTION (Execution)\n",
    "- Call a tool (search, calculator, API)\n",
    "- Query a database\n",
    "- Ask the user a question\n",
    "- Generate text\n",
    "\n",
    "**Stored in state as:** `action` and `action_input`\n",
    "\n",
    "#### OBSERVATION (Result)\n",
    "- The result of the action\n",
    "- New information learned\n",
    "- Errors or failures\n",
    "\n",
    "**Stored in state as:** `observation`\n",
    "\n",
    "---\n",
    "\n",
    "## 3.3 Why Agents Reason Between Steps, Not Inside Prompts\n",
    "\n",
    "### The Key Difference\n",
    "\n",
    "| Inside a Prompt | Between Steps |\n",
    "|-----------------|---------------|\n",
    "| \"Think about X, then Y, then Z\" | Step 1: Think â†’ Act â†’ Observe<br>Step 2: Think â†’ Act â†’ Observe |\n",
    "| LLM generates all at once | Agent executes iteratively |\n",
    "| Cannot adapt mid-reasoning | Can adapt based on observations |\n",
    "| No real-world feedback | Real-world feedback after each action |\n",
    "| Hallucination risk high | Grounded in actual observations |\n",
    "\n",
    "### Example: Why Between-Steps Matters\n",
    "\n",
    "#### Approach 1: Inside Prompt (Bad)\n",
    "\n",
    "```\n",
    "Prompt: \"\"\"\n",
    "Search for papers on transformers, \n",
    "then filter for the top 3, \n",
    "then summarize them.\n",
    "\"\"\"\n",
    "\n",
    "Result:\n",
    "\"I found papers A, B, C. \n",
    "The top 3 are A, B, C.\n",
    "Summary: ...\"\n",
    "```\n",
    "\n",
    "**Problem**: The LLM didn't actually search. It hallucinated.\n",
    "\n",
    "#### Approach 2: Between Steps (Good)\n",
    "\n",
    "```\n",
    "Step 1:\n",
    "  Thought: \"I should search\"\n",
    "  Action: search(\"transformers\")\n",
    "  Observation: [actual search results]\n",
    "\n",
    "Step 2:\n",
    "  Thought: \"I got 10 papers, I should filter\"\n",
    "  Action: filter_by_citations(top=3)\n",
    "  Observation: [3 specific papers]\n",
    "\n",
    "Step 3:\n",
    "  Thought: \"Now I can summarize these specific papers\"\n",
    "  Action: summarize([papers])\n",
    "  Observation: [actual summary based on real papers]\n",
    "```\n",
    "\n",
    "**Why This Works**:\n",
    "- âœ… Actual search happened\n",
    "- âœ… Actual papers were retrieved\n",
    "- âœ… Summary is based on real data\n",
    "- âœ… Each step is verifiable\n",
    "\n",
    "---\n",
    "\n",
    "## 3.4 Reasoning Design Checklist\n",
    "\n",
    "Use this checklist when designing agent reasoning:\n",
    "\n",
    "### â˜‘ï¸ Reasoning Design Checklist\n",
    "\n",
    "| # | Question | Check |\n",
    "|---|----------|-------|\n",
    "| 1 | Is reasoning **externalized** (not hidden in prompts)? | â˜ |\n",
    "| 2 | Is each thought **recorded in state**? | â˜ |\n",
    "| 3 | Is each action **explicitly defined**? | â˜ |\n",
    "| 4 | Is each observation **stored for future steps**? | â˜ |\n",
    "| 5 | Can I **trace the reasoning path** from start to finish? | â˜ |\n",
    "| 6 | Can I **validate** that actions were actually taken? | â˜ |\n",
    "| 7 | Can I **debug** why a decision was made? | â˜ |\n",
    "| 8 | Does reasoning **adapt** based on observations? | â˜ |\n",
    "| 9 | Is the reasoning loop **iterative** (not one-shot)? | â˜ |\n",
    "| 10 | Can I **replay** the reasoning for audit purposes? | â˜ |\n",
    "\n",
    "If you answered \"yes\" to all 10, your reasoning design is solid.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.5 Conceptual Reasoning Flow (Non-Code)\n",
    "\n",
    "Here's a template for designing reasoning flows before writing code:\n",
    "\n",
    "```\n",
    "AGENT REASONING FLOW TEMPLATE\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "GOAL: [What the agent is trying to achieve]\n",
    "\n",
    "INITIAL STATE:\n",
    "  â€¢ What we know: [Initial context]\n",
    "  â€¢ What we need: [Information gaps]\n",
    "\n",
    "REASONING LOOP:\n",
    "\n",
    "  ITERATION 1:\n",
    "    Thought: [What should I do first?]\n",
    "    Action: [What action will I take?]\n",
    "    Expected Observation: [What might I learn?]\n",
    "    State Update: [What changes in state?]\n",
    "\n",
    "  ITERATION 2:\n",
    "    Thought: [Given observation, what next?]\n",
    "    Action: [Next action]\n",
    "    Expected Observation: [What might I learn?]\n",
    "    State Update: [What changes?]\n",
    "\n",
    "  ITERATION 3:\n",
    "    ...\n",
    "\n",
    "  TERMINATION CONDITION:\n",
    "    When: [What indicates we're done?]\n",
    "    Final Output: [What do we return?]\n",
    "\n",
    "VALIDATION CHECKS:\n",
    "  â€¢ Can we verify each action was taken?\n",
    "  â€¢ Can we trace the reasoning path?\n",
    "  â€¢ Can we reproduce the result?\n",
    "```\n",
    "\n",
    "### Example: Research Agent\n",
    "\n",
    "```\n",
    "GOAL: Summarize recent papers on transformers\n",
    "\n",
    "INITIAL STATE:\n",
    "  â€¢ What we know: Topic is \"transformers\"\n",
    "  â€¢ What we need: Actual recent papers\n",
    "\n",
    "REASONING LOOP:\n",
    "\n",
    "  ITERATION 1:\n",
    "    Thought: \"I need to search for papers\"\n",
    "    Action: search_papers(query=\"transformers\", year=2024)\n",
    "    Expected Observation: List of papers with metadata\n",
    "    State Update: papers_found = [list]\n",
    "\n",
    "  ITERATION 2:\n",
    "    Thought: \"I have 20 papers, too many. I should filter.\"\n",
    "    Action: filter_by_citations(papers, top=5)\n",
    "    Expected Observation: Top 5 papers by citation\n",
    "    State Update: selected_papers = [top 5]\n",
    "\n",
    "  ITERATION 3:\n",
    "    Thought: \"Now I can read abstracts and summarize\"\n",
    "    Action: extract_abstracts(selected_papers)\n",
    "    Expected Observation: Abstract text for each paper\n",
    "    State Update: abstracts = [texts]\n",
    "\n",
    "  ITERATION 4:\n",
    "    Thought: \"I have enough information to synthesize\"\n",
    "    Action: generate_summary(abstracts)\n",
    "    Expected Observation: Summary text\n",
    "    State Update: final_summary = text\n",
    "\n",
    "  TERMINATION CONDITION:\n",
    "    When: final_summary is not None\n",
    "    Final Output: Return final_summary\n",
    "\n",
    "VALIDATION CHECKS:\n",
    "  âœ“ Verify papers_found is not empty\n",
    "  âœ“ Verify selected_papers has 5 or fewer\n",
    "  âœ“ Verify abstracts were actually extracted\n",
    "  âœ“ Verify summary references actual papers\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3.6 The Mental Shift\n",
    "\n",
    "### Old Mindset (Prompting)\n",
    "\n",
    "```\n",
    "\"I need to write the perfect prompt that\n",
    " tells the LLM exactly what to do.\"\n",
    "```\n",
    "\n",
    "### New Mindset (Reasoning)\n",
    "\n",
    "```\n",
    "\"I need to design a reasoning loop where\n",
    " the agent observes, thinks, acts, and\n",
    " adapts based on real feedback.\"\n",
    "```\n",
    "\n",
    "This shift is fundamental to building production agents.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Key Takeaway: Section 3\n",
    "\n",
    "> **Agent reasoning is a process, not a prompt. It's an iterative loop of Thought â†’ Action â†’ Observation where each step is externalized into state. Design your reasoning flow before writing code, and ensure every decision is traceable and debuggable.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1014d727",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary: Sections 1-3\n",
    "\n",
    "| Section | Key Concept |\n",
    "|---------|-------------|\n",
    "| **Section 1** | Reasoning is externalized decision-making, not internal chain-of-thought |\n",
    "| **Section 2** | Hidden reasoning breaks debuggability; artifacts must live in state |\n",
    "| **Section 3** | Reasoning is an iterative process (Thought â†’ Action â†’ Observation) |\n",
    "\n",
    "---\n",
    "\n",
    "## Next Sections Preview\n",
    "\n",
    "In upcoming sections, we will:\n",
    "\n",
    "- **Section 4:** Implement explicit reasoning patterns in code\n",
    "- **Section 5:** Store reasoning artifacts in state\n",
    "- **Section 6:** Build a complete ReAct agent\n",
    "- **Section 7:** Visualize reasoning flows\n",
    "- **Section 8:** Multi-agent reasoning coordination\n",
    "- **Section 9:** Common reasoning mistakes\n",
    "- **Section 10:** Final reasoning framework\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bebb57",
   "metadata": {},
   "source": [
    "<a id=\"section-4\"></a>\n",
    "# Section 4: Single-Agent Step-by-Step Reasoning\n",
    "\n",
    "Now let's implement a real agent with **explicit reasoning** stored in state.\n",
    "\n",
    "---\n",
    "\n",
    "## 4.1 Setup: Imports and Helper Functions\n",
    "\n",
    "First, we'll set up our imports and create helper functions for displaying reasoning state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715c9a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "from typing import TypedDict, Optional, List, Dict, Any\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Helper function to print section headers\n",
    "def print_section_header(title: str, width: int = 60):\n",
    "    \"\"\"Print a formatted section header\"\"\"\n",
    "    print(\"\\n\" + \"=\" * width)\n",
    "    print(f\"  {title}\")\n",
    "    print(\"=\" * width + \"\\n\")\n",
    "\n",
    "# Helper function to display reasoning state\n",
    "def display_reasoning_state(state: Dict[str, Any], step_number: int = None):\n",
    "    \"\"\"Display the current reasoning state in a readable format\"\"\"\n",
    "    if step_number is not None:\n",
    "        print(f\"\\n{'â”€' * 60}\")\n",
    "        print(f\"  REASONING STEP {step_number}\")\n",
    "        print('â”€' * 60)\n",
    "    \n",
    "    for key, value in state.items():\n",
    "        if isinstance(value, list) and len(value) > 3:\n",
    "            print(f\"  {key}: [{len(value)} items]\")\n",
    "        elif isinstance(value, str) and len(value) > 100:\n",
    "            print(f\"  {key}: {value[:100]}...\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    print()\n",
    "\n",
    "print(\"âœ“ Imports and helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3387eaf1",
   "metadata": {},
   "source": [
    "## 4.2 Reasoning State Schema\n",
    "\n",
    "We'll define a structured state that explicitly captures all reasoning artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReasoningStep:\n",
    "    \"\"\"A single reasoning step with thought, action, and observation\"\"\"\n",
    "    step_number: int\n",
    "    thought: str\n",
    "    action: str\n",
    "    action_input: Dict[str, Any]\n",
    "    observation: Optional[str] = None\n",
    "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "\n",
    "@dataclass\n",
    "class ResearchAgentState:\n",
    "    \"\"\"State for a research agent with explicit reasoning\"\"\"\n",
    "    goal: str\n",
    "    current_step: int = 0\n",
    "    reasoning_trace: List[ReasoningStep] = field(default_factory=list)\n",
    "    papers_found: List[Dict[str, str]] = field(default_factory=list)\n",
    "    selected_papers: List[Dict[str, str]] = field(default_factory=list)\n",
    "    final_summary: Optional[str] = None\n",
    "    is_complete: bool = False\n",
    "    \n",
    "    def add_reasoning_step(self, thought: str, action: str, action_input: Dict[str, Any], observation: Optional[str] = None):\n",
    "        \"\"\"Add a new reasoning step to the trace\"\"\"\n",
    "        self.current_step += 1\n",
    "        step = ReasoningStep(\n",
    "            step_number=self.current_step,\n",
    "            thought=thought,\n",
    "            action=action,\n",
    "            action_input=action_input,\n",
    "            observation=observation\n",
    "        )\n",
    "        self.reasoning_trace.append(step)\n",
    "        return step\n",
    "    \n",
    "    def get_latest_step(self) -> Optional[ReasoningStep]:\n",
    "        \"\"\"Get the most recent reasoning step\"\"\"\n",
    "        return self.reasoning_trace[-1] if self.reasoning_trace else None\n",
    "\n",
    "# Create an example state\n",
    "example_state = ResearchAgentState(goal=\"Summarize recent papers on transformers\")\n",
    "print(\"âœ“ ResearchAgentState schema defined\")\n",
    "print(\"\\nInitial state:\")\n",
    "print(f\"  Goal: {example_state.goal}\")\n",
    "print(f\"  Current step: {example_state.current_step}\")\n",
    "print(f\"  Reasoning trace: {len(example_state.reasoning_trace)} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf06dd0",
   "metadata": {},
   "source": [
    "## 4.3 Simulated Tools (Mock Functions)\n",
    "\n",
    "Since we don't have real APIs, we'll simulate search and retrieval functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcbd84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated database of papers\n",
    "MOCK_PAPER_DATABASE = [\n",
    "    {\"title\": \"Attention Is All You Need\", \"year\": 2017, \"citations\": 95000, \"abstract\": \"We propose the Transformer...\"},\n",
    "    {\"title\": \"BERT: Pre-training of Deep Bidirectional Transformers\", \"year\": 2018, \"citations\": 75000, \"abstract\": \"We introduce BERT...\"},\n",
    "    {\"title\": \"GPT-3: Language Models are Few-Shot Learners\", \"year\": 2020, \"citations\": 50000, \"abstract\": \"We show that scaling up language models...\"},\n",
    "    {\"title\": \"Vision Transformer\", \"year\": 2021, \"citations\": 30000, \"abstract\": \"We apply transformers to image recognition...\"},\n",
    "    {\"title\": \"Flamingo: Visual Language Models\", \"year\": 2022, \"citations\": 15000, \"abstract\": \"We present Flamingo...\"},\n",
    "    {\"title\": \"LLaMA: Open Foundation Models\", \"year\": 2023, \"citations\": 12000, \"abstract\": \"We release LLaMA...\"},\n",
    "    {\"title\": \"Mixtral: Mixture of Experts\", \"year\": 2024, \"citations\": 5000, \"abstract\": \"We present Mixtral...\"},\n",
    "    {\"title\": \"Transformers for Time Series\", \"year\": 2024, \"citations\": 3000, \"abstract\": \"We adapt transformers for time series...\"},\n",
    "]\n",
    "\n",
    "def search_papers(query: str, year_from: int = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Simulate searching for papers\"\"\"\n",
    "    results = MOCK_PAPER_DATABASE.copy()\n",
    "    \n",
    "    # Filter by year if specified\n",
    "    if year_from:\n",
    "        results = [p for p in results if p[\"year\"] >= year_from]\n",
    "    \n",
    "    # Simple keyword matching (just for demo)\n",
    "    query_lower = query.lower()\n",
    "    if \"vision\" in query_lower or \"image\" in query_lower:\n",
    "        results = [p for p in results if \"vision\" in p[\"title\"].lower() or \"image\" in p[\"abstract\"].lower()]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def filter_papers_by_citations(papers: List[Dict[str, Any]], top_n: int = 3) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Filter papers by citation count\"\"\"\n",
    "    sorted_papers = sorted(papers, key=lambda x: x[\"citations\"], reverse=True)\n",
    "    return sorted_papers[:top_n]\n",
    "\n",
    "def extract_abstracts(papers: List[Dict[str, Any]]) -> List[str]:\n",
    "    \"\"\"Extract abstracts from papers\"\"\"\n",
    "    return [p[\"abstract\"] for p in papers]\n",
    "\n",
    "def synthesize_summary(abstracts: List[str], papers: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"Generate a summary from abstracts (simulated)\"\"\"\n",
    "    titles = [p[\"title\"] for p in papers]\n",
    "    summary = f\"Analysis of {len(papers)} papers: {', '.join(titles)}.\\n\"\n",
    "    summary += f\"Key findings: These papers demonstrate the evolution of transformer architectures \"\n",
    "    summary += f\"from the original attention mechanism to modern applications.\"\n",
    "    return summary\n",
    "\n",
    "print(\"âœ“ Mock tools defined (search_papers, filter_papers_by_citations, extract_abstracts, synthesize_summary)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172a9e0",
   "metadata": {},
   "source": [
    "## 4.4 Implementing the Research Agent\n",
    "\n",
    "Now we'll implement an agent that **explicitly reasons** through each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e01ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_agent_step_1_search(state: ResearchAgentState) -> ResearchAgentState:\n",
    "    \"\"\"Step 1: Search for papers\"\"\"\n",
    "    # THOUGHT: What should I do?\n",
    "    thought = \"I need to search for recent papers on transformers\"\n",
    "    \n",
    "    # ACTION: What will I do?\n",
    "    action = \"search_papers\"\n",
    "    action_input = {\"query\": \"transformers\", \"year_from\": 2020}\n",
    "    \n",
    "    # Execute the action\n",
    "    papers = search_papers(**action_input)\n",
    "    \n",
    "    # OBSERVATION: What did I learn?\n",
    "    observation = f\"Found {len(papers)} papers from 2020 onwards\"\n",
    "    \n",
    "    # Record the reasoning step\n",
    "    state.add_reasoning_step(thought, action, action_input, observation)\n",
    "    \n",
    "    # Update state with results\n",
    "    state.papers_found = papers\n",
    "    \n",
    "    return state\n",
    "\n",
    "def research_agent_step_2_filter(state: ResearchAgentState) -> ResearchAgentState:\n",
    "    \"\"\"Step 2: Filter papers by relevance\"\"\"\n",
    "    # THOUGHT: Given what I know, what next?\n",
    "    thought = f\"I found {len(state.papers_found)} papers. I should filter to the most cited ones.\"\n",
    "    \n",
    "    # ACTION: What will I do?\n",
    "    action = \"filter_papers_by_citations\"\n",
    "    action_input = {\"papers\": \"papers_found\", \"top_n\": 3}\n",
    "    \n",
    "    # Execute the action\n",
    "    selected = filter_papers_by_citations(state.papers_found, top_n=3)\n",
    "    \n",
    "    # OBSERVATION: What did I learn?\n",
    "    observation = f\"Selected top 3 papers by citations: {[p['title'] for p in selected]}\"\n",
    "    \n",
    "    # Record the reasoning step\n",
    "    state.add_reasoning_step(thought, action, action_input, observation)\n",
    "    \n",
    "    # Update state with results\n",
    "    state.selected_papers = selected\n",
    "    \n",
    "    return state\n",
    "\n",
    "def research_agent_step_3_extract(state: ResearchAgentState) -> ResearchAgentState:\n",
    "    \"\"\"Step 3: Extract abstracts\"\"\"\n",
    "    # THOUGHT: What's next?\n",
    "    thought = \"Now I need to read the abstracts of the selected papers\"\n",
    "    \n",
    "    # ACTION: What will I do?\n",
    "    action = \"extract_abstracts\"\n",
    "    action_input = {\"papers\": \"selected_papers\"}\n",
    "    \n",
    "    # Execute the action\n",
    "    abstracts = extract_abstracts(state.selected_papers)\n",
    "    \n",
    "    # OBSERVATION: What did I learn?\n",
    "    observation = f\"Extracted {len(abstracts)} abstracts\"\n",
    "    \n",
    "    # Record the reasoning step\n",
    "    state.add_reasoning_step(thought, action, action_input, observation)\n",
    "    \n",
    "    return state\n",
    "\n",
    "def research_agent_step_4_synthesize(state: ResearchAgentState) -> ResearchAgentState:\n",
    "    \"\"\"Step 4: Synthesize summary\"\"\"\n",
    "    # THOUGHT: Am I ready to conclude?\n",
    "    thought = \"I have the abstracts. Now I can synthesize a summary.\"\n",
    "    \n",
    "    # ACTION: What will I do?\n",
    "    action = \"synthesize_summary\"\n",
    "    action_input = {\"abstracts\": \"extracted\", \"papers\": \"selected_papers\"}\n",
    "    \n",
    "    # Execute the action\n",
    "    abstracts = extract_abstracts(state.selected_papers)\n",
    "    summary = synthesize_summary(abstracts, state.selected_papers)\n",
    "    \n",
    "    # OBSERVATION: What's the result?\n",
    "    observation = \"Summary generated successfully\"\n",
    "    \n",
    "    # Record the reasoning step\n",
    "    state.add_reasoning_step(thought, action, action_input, observation)\n",
    "    \n",
    "    # Update state with final result\n",
    "    state.final_summary = summary\n",
    "    state.is_complete = True\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"âœ“ Research agent steps defined (step_1_search, step_2_filter, step_3_extract, step_4_synthesize)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f05f2",
   "metadata": {},
   "source": [
    "## 4.5 Running the Agent and Observing Reasoning\n",
    "\n",
    "Let's execute each step and observe the reasoning evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"RESEARCH AGENT EXECUTION\")\n",
    "\n",
    "# Initialize state\n",
    "state = ResearchAgentState(goal=\"Summarize recent transformer papers\")\n",
    "\n",
    "print(f\"Initial Goal: {state.goal}\\n\")\n",
    "\n",
    "# Execute Step 1\n",
    "print(\"â–¶ Executing Step 1: Search\")\n",
    "state = research_agent_step_1_search(state)\n",
    "latest_step = state.get_latest_step()\n",
    "print(f\"  Thought: {latest_step.thought}\")\n",
    "print(f\"  Action: {latest_step.action}({latest_step.action_input})\")\n",
    "print(f\"  Observation: {latest_step.observation}\")\n",
    "print(f\"  Papers found: {len(state.papers_found)}\")\n",
    "\n",
    "# Execute Step 2\n",
    "print(\"\\nâ–¶ Executing Step 2: Filter\")\n",
    "state = research_agent_step_2_filter(state)\n",
    "latest_step = state.get_latest_step()\n",
    "print(f\"  Thought: {latest_step.thought}\")\n",
    "print(f\"  Action: {latest_step.action}({latest_step.action_input})\")\n",
    "print(f\"  Observation: {latest_step.observation}\")\n",
    "print(f\"  Selected papers: {len(state.selected_papers)}\")\n",
    "\n",
    "# Execute Step 3\n",
    "print(\"\\nâ–¶ Executing Step 3: Extract Abstracts\")\n",
    "state = research_agent_step_3_extract(state)\n",
    "latest_step = state.get_latest_step()\n",
    "print(f\"  Thought: {latest_step.thought}\")\n",
    "print(f\"  Action: {latest_step.action}({latest_step.action_input})\")\n",
    "print(f\"  Observation: {latest_step.observation}\")\n",
    "\n",
    "# Execute Step 4\n",
    "print(\"\\nâ–¶ Executing Step 4: Synthesize Summary\")\n",
    "state = research_agent_step_4_synthesize(state)\n",
    "latest_step = state.get_latest_step()\n",
    "print(f\"  Thought: {latest_step.thought}\")\n",
    "print(f\"  Action: {latest_step.action}({latest_step.action_input})\")\n",
    "print(f\"  Observation: {latest_step.observation}\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"FINAL RESULT\")\n",
    "print('=' * 60)\n",
    "print(f\"Complete: {state.is_complete}\")\n",
    "print(f\"Summary: {state.final_summary}\")\n",
    "print(f\"\\nTotal reasoning steps: {len(state.reasoning_trace)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1880932e",
   "metadata": {},
   "source": [
    "## 4.6 Inspecting the Complete Reasoning Trace\n",
    "\n",
    "Let's examine the full reasoning trace to see every decision the agent made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec59950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"COMPLETE REASONING TRACE\")\n",
    "\n",
    "for step in state.reasoning_trace:\n",
    "    print(f\"Step {step.step_number}:\")\n",
    "    print(f\"  ğŸ’­ Thought: {step.thought}\")\n",
    "    print(f\"  ğŸ”§ Action: {step.action}\")\n",
    "    print(f\"  ğŸ“¥ Input: {step.action_input}\")\n",
    "    print(f\"  ğŸ‘ï¸  Observation: {step.observation}\")\n",
    "    print(f\"  ğŸ• Timestamp: {step.timestamp}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"WHY THIS MATTERS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "âœ… Every decision is recorded\n",
    "âœ… Every action is traceable\n",
    "âœ… Every observation is logged\n",
    "âœ… We can debug each step\n",
    "âœ… We can validate correctness\n",
    "âœ… We can audit the reasoning process\n",
    "\n",
    "This is the difference between:\n",
    "  âŒ \"The agent said it searched\" (unverifiable)\n",
    "  âœ… \"The agent searched and found 5 papers\" (verified in state)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be8197",
   "metadata": {},
   "source": [
    "## ğŸ¯ Key Takeaway: Section 4\n",
    "\n",
    "> **By externalizing reasoning into structured state, we transform agent behavior from a black box into a transparent, debuggable, auditable process. Every thought, action, and observation becomes a first-class artifact that can be inspected, validated, and replayed.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcbb6d1",
   "metadata": {},
   "source": [
    "<a id=\"section-5\"></a>\n",
    "# Section 5: Reasoning Validation & Evaluation\n",
    "\n",
    "Having reasoning in state is not enoughâ€”we must **validate** that the reasoning is correct.\n",
    "\n",
    "---\n",
    "\n",
    "## 5.1 Why Validation Matters\n",
    "\n",
    "Without validation, agents can:\n",
    "- Skip critical reasoning steps\n",
    "- Hallucinate conclusions without evidence\n",
    "- Claim to have done work they never did\n",
    "- Produce unreliable results\n",
    "\n",
    "**Validation ensures the reasoning trace reflects actual execution.**\n",
    "\n",
    "---\n",
    "\n",
    "## 5.2 Validation Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92174882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReasoningValidationError(Exception):\n",
    "    \"\"\"Raised when reasoning validation fails\"\"\"\n",
    "    pass\n",
    "\n",
    "def validate_reasoning_sequence(state: ResearchAgentState, expected_actions: List[str]) -> bool:\n",
    "    \"\"\"Validate that reasoning steps occurred in the expected order\"\"\"\n",
    "    actual_actions = [step.action for step in state.reasoning_trace]\n",
    "    \n",
    "    if len(actual_actions) != len(expected_actions):\n",
    "        raise ReasoningValidationError(\n",
    "            f\"Expected {len(expected_actions)} steps, but found {len(actual_actions)}\"\n",
    "        )\n",
    "    \n",
    "    for i, (actual, expected) in enumerate(zip(actual_actions, expected_actions)):\n",
    "        if actual != expected:\n",
    "            raise ReasoningValidationError(\n",
    "                f\"Step {i+1}: Expected action '{expected}', but found '{actual}'\"\n",
    "            )\n",
    "    \n",
    "    print(f\"âœ“ Reasoning sequence validated: {len(expected_actions)} steps in correct order\")\n",
    "    return True\n",
    "\n",
    "def validate_no_skipped_steps(state: ResearchAgentState) -> bool:\n",
    "    \"\"\"Ensure no steps were skipped\"\"\"\n",
    "    for i, step in enumerate(state.reasoning_trace, 1):\n",
    "        if step.step_number != i:\n",
    "            raise ReasoningValidationError(\n",
    "                f\"Step numbering error: Expected step {i}, found step {step.step_number}\"\n",
    "            )\n",
    "    \n",
    "    print(f\"âœ“ No skipped steps: All {len(state.reasoning_trace)} steps present\")\n",
    "    return True\n",
    "\n",
    "def validate_observations_exist(state: ResearchAgentState) -> bool:\n",
    "    \"\"\"Ensure all reasoning steps have observations\"\"\"\n",
    "    for step in state.reasoning_trace:\n",
    "        if step.observation is None or step.observation == \"\":\n",
    "            raise ReasoningValidationError(\n",
    "                f\"Step {step.step_number} has no observation (possible hallucination)\"\n",
    "            )\n",
    "    \n",
    "    print(f\"âœ“ All {len(state.reasoning_trace)} steps have observations\")\n",
    "    return True\n",
    "\n",
    "def validate_evidence_before_conclusion(state: ResearchAgentState) -> bool:\n",
    "    \"\"\"Ensure evidence was gathered before final conclusion\"\"\"\n",
    "    if state.is_complete and state.final_summary:\n",
    "        # Check that we have selected papers\n",
    "        if not state.selected_papers:\n",
    "            raise ReasoningValidationError(\n",
    "                \"Final summary generated without selecting any papers (hallucination)\"\n",
    "            )\n",
    "        \n",
    "        # Check that we actually searched\n",
    "        search_steps = [s for s in state.reasoning_trace if s.action == \"search_papers\"]\n",
    "        if not search_steps:\n",
    "            raise ReasoningValidationError(\n",
    "                \"Final summary generated without searching for papers\"\n",
    "            )\n",
    "        \n",
    "        print(\"âœ“ Evidence validated: Summary based on actual retrieved papers\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"âœ“ Validation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e4b8e",
   "metadata": {},
   "source": [
    "## 5.3 Validating Our Research Agent\n",
    "\n",
    "Let's validate the reasoning trace from Section 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d752997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"VALIDATING RESEARCH AGENT REASONING\")\n",
    "\n",
    "# Define expected sequence\n",
    "expected_sequence = [\n",
    "    \"search_papers\",\n",
    "    \"filter_papers_by_citations\", \n",
    "    \"extract_abstracts\",\n",
    "    \"synthesize_summary\"\n",
    "]\n",
    "\n",
    "# Run all validations\n",
    "try:\n",
    "    validate_reasoning_sequence(state, expected_sequence)\n",
    "    validate_no_skipped_steps(state)\n",
    "    validate_observations_exist(state)\n",
    "    validate_evidence_before_conclusion(state)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âœ… ALL VALIDATIONS PASSED\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"The reasoning trace is valid and trustworthy.\")\n",
    "    \n",
    "except ReasoningValidationError as e:\n",
    "    print(f\"\\nâŒ VALIDATION FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e022d97f",
   "metadata": {},
   "source": [
    "## 5.4 Failure Case: Skipped Reasoning\n",
    "\n",
    "Let's demonstrate what happens when an agent skips a critical step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4994457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"FAILURE CASE: Skipped Search Step\")\n",
    "\n",
    "# Create a broken agent that skips the search step\n",
    "broken_state = ResearchAgentState(goal=\"Summarize papers\")\n",
    "\n",
    "# Oops! Skip search and go straight to filtering (WRONG!)\n",
    "broken_state.add_reasoning_step(\n",
    "    thought=\"I'll just filter papers\",\n",
    "    action=\"filter_papers_by_citations\",\n",
    "    action_input={\"papers\": [], \"top_n\": 3},\n",
    "    observation=\"No papers to filter\"\n",
    ")\n",
    "\n",
    "# Try to synthesize without data\n",
    "broken_state.add_reasoning_step(\n",
    "    thought=\"I'll synthesize a summary\",\n",
    "    action=\"synthesize_summary\",\n",
    "    action_input={\"abstracts\": [], \"papers\": []},\n",
    "    observation=\"Summary generated\"\n",
    ")\n",
    "\n",
    "# Hallucinate a summary\n",
    "broken_state.final_summary = \"Based on recent papers, transformers are very popular...\"\n",
    "broken_state.is_complete = True\n",
    "\n",
    "print(\"Broken agent created (skipped search step)\")\n",
    "print(f\"Reasoning steps: {len(broken_state.reasoning_trace)}\")\n",
    "print(f\"Papers found: {len(broken_state.papers_found)}\")\n",
    "print(f\"Summary: {broken_state.final_summary}\")\n",
    "\n",
    "# Now try to validate\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Attempting validation...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "try:\n",
    "    validate_evidence_before_conclusion(broken_state)\n",
    "    print(\"âœ… Validation passed (this should NOT happen)\")\n",
    "except ReasoningValidationError as e:\n",
    "    print(f\"âŒ Validation caught the error!\")\n",
    "    print(f\"   Error: {e}\")\n",
    "    print(\"\\nâœ“ This is GOOD - validation detected the hallucination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c51a7",
   "metadata": {},
   "source": [
    "## 5.5 Corrected Reasoning Trace\n",
    "\n",
    "Now let's show the corrected version with proper reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42753ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"CORRECTED: Proper Reasoning Trace\")\n",
    "\n",
    "# Create a corrected agent\n",
    "corrected_state = ResearchAgentState(goal=\"Summarize papers\")\n",
    "\n",
    "# Step 1: Actually search\n",
    "corrected_state = research_agent_step_1_search(corrected_state)\n",
    "print(f\"âœ“ Step 1: Searched and found {len(corrected_state.papers_found)} papers\")\n",
    "\n",
    "# Step 2: Filter\n",
    "corrected_state = research_agent_step_2_filter(corrected_state)\n",
    "print(f\"âœ“ Step 2: Filtered to {len(corrected_state.selected_papers)} papers\")\n",
    "\n",
    "# Step 3: Extract\n",
    "corrected_state = research_agent_step_3_extract(corrected_state)\n",
    "print(f\"âœ“ Step 3: Extracted abstracts\")\n",
    "\n",
    "# Step 4: Synthesize\n",
    "corrected_state = research_agent_step_4_synthesize(corrected_state)\n",
    "print(f\"âœ“ Step 4: Generated summary\")\n",
    "\n",
    "# Now validate\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Validating corrected reasoning...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "try:\n",
    "    validate_evidence_before_conclusion(corrected_state)\n",
    "    print(\"\\nâœ… VALIDATION PASSED\")\n",
    "    print(\"The corrected agent has proper evidence for its conclusions.\")\n",
    "except ReasoningValidationError as e:\n",
    "    print(f\"âŒ Validation failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Broken agent:    {len(broken_state.papers_found)} papers, {len(broken_state.reasoning_trace)} steps\")\n",
    "print(f\"Corrected agent: {len(corrected_state.papers_found)} papers, {len(corrected_state.reasoning_trace)} steps\")\n",
    "print(\"\\nThe corrected agent has actual evidence supporting its conclusions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14bf5fb",
   "metadata": {},
   "source": [
    "## ğŸ¯ Key Takeaway: Section 5\n",
    "\n",
    "> **Reasoning without evaluation is unreliable. Validation functions ensure that agents don't skip steps, hallucinate conclusions, or claim work they never did. Always validate that evidence exists before accepting conclusions.**\n",
    "\n",
    "**Critical principle:** If you can't validate the reasoning, you can't trust the result.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85da021",
   "metadata": {},
   "source": [
    "<a id=\"section-6\"></a>\n",
    "# Section 6: Reasoning in a RAG Agent\n",
    "\n",
    "Now let's apply explicit reasoning to a **Retrieval-Augmented Generation (RAG)** agent.\n",
    "\n",
    "---\n",
    "\n",
    "## 6.1 Why RAG Needs Explicit Reasoning\n",
    "\n",
    "RAG agents must reason about:\n",
    "1. **Query Analysis**: What information do I need?\n",
    "2. **Retrieval Decision**: Where should I search?\n",
    "3. **Evidence Selection**: Which documents are relevant?\n",
    "4. **Answer Synthesis**: How do I combine evidence into an answer?\n",
    "\n",
    "Without explicit reasoning, RAG agents can:\n",
    "- âŒ Cite non-existent documents\n",
    "- âŒ Generate answers without retrieval\n",
    "- âŒ Use irrelevant evidence\n",
    "- âŒ Make unjustified inferences\n",
    "\n",
    "---\n",
    "\n",
    "## 6.2 RAG Agent State Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ac75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Document:\n",
    "    \"\"\"A retrieved document\"\"\"\n",
    "    id: str\n",
    "    content: str\n",
    "    source: str\n",
    "    relevance_score: float = 0.0\n",
    "\n",
    "@dataclass\n",
    "class RAGReasoningStep:\n",
    "    \"\"\"Reasoning step specific to RAG\"\"\"\n",
    "    step_number: int\n",
    "    phase: str  # \"query_analysis\", \"retrieval\", \"selection\", \"synthesis\"\n",
    "    reasoning: str\n",
    "    action: str\n",
    "    evidence: List[Document] = field(default_factory=list)\n",
    "    decision: str = \"\"\n",
    "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "\n",
    "@dataclass\n",
    "class RAGAgentState:\n",
    "    \"\"\"State for a RAG agent with explicit reasoning\"\"\"\n",
    "    query: str\n",
    "    reasoning_trace: List[RAGReasoningStep] = field(default_factory=list)\n",
    "    retrieved_documents: List[Document] = field(default_factory=list)\n",
    "    selected_documents: List[Document] = field(default_factory=list)\n",
    "    final_answer: Optional[str] = None\n",
    "    current_step: int = 0\n",
    "    \n",
    "    def add_reasoning_step(self, phase: str, reasoning: str, action: str, \n",
    "                          evidence: List[Document] = None, decision: str = \"\"):\n",
    "        \"\"\"Add a RAG reasoning step\"\"\"\n",
    "        self.current_step += 1\n",
    "        step = RAGReasoningStep(\n",
    "            step_number=self.current_step,\n",
    "            phase=phase,\n",
    "            reasoning=reasoning,\n",
    "            action=action,\n",
    "            evidence=evidence or [],\n",
    "            decision=decision\n",
    "        )\n",
    "        self.reasoning_trace.append(step)\n",
    "        return step\n",
    "\n",
    "print(\"âœ“ RAG agent state schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21810f73",
   "metadata": {},
   "source": [
    "## 6.3 Mock Document Database and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac43b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock document database\n",
    "MOCK_DOCUMENTS = [\n",
    "    Document(id=\"doc1\", content=\"Transformers use self-attention mechanisms to process sequences in parallel.\", \n",
    "             source=\"paper_attention.pdf\", relevance_score=0.95),\n",
    "    Document(id=\"doc2\", content=\"BERT is a bidirectional encoder trained on masked language modeling.\", \n",
    "             source=\"paper_bert.pdf\", relevance_score=0.88),\n",
    "    Document(id=\"doc3\", content=\"GPT models are autoregressive transformers trained on next-token prediction.\", \n",
    "             source=\"paper_gpt.pdf\", relevance_score=0.92),\n",
    "    Document(id=\"doc4\", content=\"Vision transformers apply the transformer architecture to image patches.\", \n",
    "             source=\"paper_vit.pdf\", relevance_score=0.75),\n",
    "    Document(id=\"doc5\", content=\"The weather today is sunny with a chance of rain.\", \n",
    "             source=\"weather.txt\", relevance_score=0.05),  # Irrelevant document\n",
    "]\n",
    "\n",
    "def retrieve_documents(query: str, top_k: int = 5) -> List[Document]:\n",
    "    \"\"\"Simulate document retrieval\"\"\"\n",
    "    # Simple keyword matching for demo\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Score documents based on keyword overlap\n",
    "    scored_docs = []\n",
    "    for doc in MOCK_DOCUMENTS:\n",
    "        score = doc.relevance_score\n",
    "        # Boost score if query keywords appear\n",
    "        if any(word in doc.content.lower() for word in query_lower.split()):\n",
    "            score *= 1.2\n",
    "        \n",
    "        scored_docs.append((doc, score))\n",
    "    \n",
    "    # Sort by score and return top_k\n",
    "    scored_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, score in scored_docs[:top_k]]\n",
    "\n",
    "def select_relevant_documents(documents: List[Document], threshold: float = 0.7) -> List[Document]:\n",
    "    \"\"\"Filter documents by relevance threshold\"\"\"\n",
    "    return [doc for doc in documents if doc.relevance_score >= threshold]\n",
    "\n",
    "def synthesize_answer(query: str, documents: List[Document]) -> str:\n",
    "    \"\"\"Generate answer from selected documents\"\"\"\n",
    "    if not documents:\n",
    "        return \"I don't have enough information to answer this question.\"\n",
    "    \n",
    "    # Simple synthesis (in real system, would use LLM)\n",
    "    doc_contents = \" \".join([doc.content for doc in documents])\n",
    "    sources = \", \".join([doc.source for doc in documents])\n",
    "    \n",
    "    answer = f\"Based on the retrieved documents: {doc_contents[:200]}...\\n\\n\"\n",
    "    answer += f\"Sources: {sources}\"\n",
    "    return answer\n",
    "\n",
    "print(\"âœ“ Mock RAG tools defined (retrieve_documents, select_relevant_documents, synthesize_answer)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a95717d",
   "metadata": {},
   "source": [
    "## 6.4 Implementing the RAG Agent with Explicit Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76354606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_step_1_query_analysis(state: RAGAgentState) -> RAGAgentState:\n",
    "    \"\"\"Step 1: Analyze the query\"\"\"\n",
    "    reasoning = f\"The user is asking: '{state.query}'. I need to identify what information to retrieve.\"\n",
    "    decision = \"Search for documents about transformers and attention mechanisms\"\n",
    "    \n",
    "    state.add_reasoning_step(\n",
    "        phase=\"query_analysis\",\n",
    "        reasoning=reasoning,\n",
    "        action=\"analyze_query\",\n",
    "        decision=decision\n",
    "    )\n",
    "    \n",
    "    return state\n",
    "\n",
    "def rag_step_2_retrieval(state: RAGAgentState) -> RAGAgentState:\n",
    "    \"\"\"Step 2: Retrieve relevant documents\"\"\"\n",
    "    reasoning = \"I will search the document database for relevant content\"\n",
    "    \n",
    "    # Actually retrieve documents\n",
    "    docs = retrieve_documents(state.query, top_k=5)\n",
    "    \n",
    "    decision = f\"Retrieved {len(docs)} documents from the database\"\n",
    "    \n",
    "    state.add_reasoning_step(\n",
    "        phase=\"retrieval\",\n",
    "        reasoning=reasoning,\n",
    "        action=\"retrieve_documents\",\n",
    "        evidence=docs,\n",
    "        decision=decision\n",
    "    )\n",
    "    \n",
    "    state.retrieved_documents = docs\n",
    "    return state\n",
    "\n",
    "def rag_step_3_selection(state: RAGAgentState) -> RAGAgentState:\n",
    "    \"\"\"Step 3: Select relevant documents\"\"\"\n",
    "    reasoning = f\"I retrieved {len(state.retrieved_documents)} documents. I need to filter for relevance.\"\n",
    "    \n",
    "    # Filter documents\n",
    "    selected = select_relevant_documents(state.retrieved_documents, threshold=0.7)\n",
    "    \n",
    "    decision = f\"Selected {len(selected)} documents with relevance >= 0.7\"\n",
    "    \n",
    "    state.add_reasoning_step(\n",
    "        phase=\"selection\",\n",
    "        reasoning=reasoning,\n",
    "        action=\"filter_by_relevance\",\n",
    "        evidence=selected,\n",
    "        decision=decision\n",
    "    )\n",
    "    \n",
    "    state.selected_documents = selected\n",
    "    return state\n",
    "\n",
    "def rag_step_4_synthesis(state: RAGAgentState) -> RAGAgentState:\n",
    "    \"\"\"Step 4: Synthesize answer from evidence\"\"\"\n",
    "    reasoning = f\"I have {len(state.selected_documents)} relevant documents. I can now generate an answer.\"\n",
    "    \n",
    "    # Synthesize answer\n",
    "    answer = synthesize_answer(state.query, state.selected_documents)\n",
    "    \n",
    "    decision = \"Generated answer based on retrieved evidence\"\n",
    "    \n",
    "    state.add_reasoning_step(\n",
    "        phase=\"synthesis\",\n",
    "        reasoning=reasoning,\n",
    "        action=\"synthesize_answer\",\n",
    "        evidence=state.selected_documents,\n",
    "        decision=decision\n",
    "    )\n",
    "    \n",
    "    state.final_answer = answer\n",
    "    return state\n",
    "\n",
    "print(\"âœ“ RAG agent steps defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee4b176",
   "metadata": {},
   "source": [
    "## 6.5 Running the RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"RAG AGENT EXECUTION\")\n",
    "\n",
    "# Initialize RAG state\n",
    "rag_state = RAGAgentState(query=\"How do transformers work?\")\n",
    "\n",
    "print(f\"Query: {rag_state.query}\\n\")\n",
    "\n",
    "# Step 1: Query Analysis\n",
    "print(\"â–¶ Step 1: Query Analysis\")\n",
    "rag_state = rag_step_1_query_analysis(rag_state)\n",
    "step = rag_state.reasoning_trace[-1]\n",
    "print(f\"  Phase: {step.phase}\")\n",
    "print(f\"  Reasoning: {step.reasoning}\")\n",
    "print(f\"  Decision: {step.decision}\")\n",
    "\n",
    "# Step 2: Retrieval\n",
    "print(\"\\nâ–¶ Step 2: Document Retrieval\")\n",
    "rag_state = rag_step_2_retrieval(rag_state)\n",
    "step = rag_state.reasoning_trace[-1]\n",
    "print(f\"  Phase: {step.phase}\")\n",
    "print(f\"  Reasoning: {step.reasoning}\")\n",
    "print(f\"  Decision: {step.decision}\")\n",
    "print(f\"  Retrieved: {len(rag_state.retrieved_documents)} documents\")\n",
    "\n",
    "# Step 3: Selection\n",
    "print(\"\\nâ–¶ Step 3: Evidence Selection\")\n",
    "rag_state = rag_step_3_selection(rag_state)\n",
    "step = rag_state.reasoning_trace[-1]\n",
    "print(f\"  Phase: {step.phase}\")\n",
    "print(f\"  Reasoning: {step.reasoning}\")\n",
    "print(f\"  Decision: {step.decision}\")\n",
    "print(f\"  Selected: {len(rag_state.selected_documents)} documents\")\n",
    "for doc in rag_state.selected_documents:\n",
    "    print(f\"    - {doc.source} (relevance: {doc.relevance_score})\")\n",
    "\n",
    "# Step 4: Synthesis\n",
    "print(\"\\nâ–¶ Step 4: Answer Synthesis\")\n",
    "rag_state = rag_step_4_synthesis(rag_state)\n",
    "step = rag_state.reasoning_trace[-1]\n",
    "print(f\"  Phase: {step.phase}\")\n",
    "print(f\"  Reasoning: {step.reasoning}\")\n",
    "print(f\"  Decision: {step.decision}\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"FINAL ANSWER\")\n",
    "print('=' * 60)\n",
    "print(rag_state.final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8ab2a5",
   "metadata": {},
   "source": [
    "## 6.6 Validating RAG Reasoning\n",
    "\n",
    "Critical validation: ensure evidence exists before synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_rag_reasoning(state: RAGAgentState) -> bool:\n",
    "    \"\"\"Validate that RAG agent followed proper reasoning\"\"\"\n",
    "    \n",
    "    # Check 1: Evidence exists before synthesis\n",
    "    synthesis_steps = [s for s in state.reasoning_trace if s.phase == \"synthesis\"]\n",
    "    if synthesis_steps:\n",
    "        if not state.selected_documents:\n",
    "            raise ReasoningValidationError(\n",
    "                \"Answer was synthesized without selecting any documents (hallucination)\"\n",
    "            )\n",
    "        print(\"âœ“ Evidence exists before synthesis\")\n",
    "    \n",
    "    # Check 2: Retrieval happened before selection\n",
    "    retrieval_steps = [s for s in state.reasoning_trace if s.phase == \"retrieval\"]\n",
    "    selection_steps = [s for s in state.reasoning_trace if s.phase == \"selection\"]\n",
    "    \n",
    "    if selection_steps and not retrieval_steps:\n",
    "        raise ReasoningValidationError(\n",
    "            \"Selection happened without retrieval\"\n",
    "        )\n",
    "    print(\"âœ“ Retrieval occurred before selection\")\n",
    "    \n",
    "    # Check 3: Reasoning references retrieved content\n",
    "    if state.final_answer and state.selected_documents:\n",
    "        # Check that answer isn't empty\n",
    "        if not state.final_answer or len(state.final_answer) < 10:\n",
    "            raise ReasoningValidationError(\n",
    "                \"Final answer is too short or empty\"\n",
    "            )\n",
    "        print(\"âœ“ Final answer generated from evidence\")\n",
    "    \n",
    "    # Check 4: All steps have reasoning recorded\n",
    "    for step in state.reasoning_trace:\n",
    "        if not step.reasoning:\n",
    "            raise ReasoningValidationError(\n",
    "                f\"Step {step.step_number} ({step.phase}) has no reasoning recorded\"\n",
    "            )\n",
    "    print(f\"âœ“ All {len(state.reasoning_trace)} steps have reasoning recorded\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "print_section_header(\"VALIDATING RAG AGENT\")\n",
    "\n",
    "try:\n",
    "    validate_rag_reasoning(rag_state)\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âœ… RAG REASONING VALIDATED\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"The agent:\")\n",
    "    print(\"  â€¢ Actually retrieved documents\")\n",
    "    print(\"  â€¢ Selected relevant evidence\")\n",
    "    print(\"  â€¢ Generated answer based on real evidence\")\n",
    "    print(\"  â€¢ Recorded all reasoning decisions\")\n",
    "except ReasoningValidationError as e:\n",
    "    print(f\"\\nâŒ VALIDATION FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3288be",
   "metadata": {},
   "source": [
    "## 6.7 Inspecting RAG Reasoning Trace\n",
    "\n",
    "Let's examine the complete reasoning trace to verify every decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a3ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"COMPLETE RAG REASONING TRACE\")\n",
    "\n",
    "for step in rag_state.reasoning_trace:\n",
    "    print(f\"Step {step.step_number}: {step.phase.upper()}\")\n",
    "    print(f\"  ğŸ’­ Reasoning: {step.reasoning}\")\n",
    "    print(f\"  ğŸ”§ Action: {step.action}\")\n",
    "    print(f\"  ğŸ“Š Evidence: {len(step.evidence)} documents\")\n",
    "    if step.evidence:\n",
    "        for doc in step.evidence[:2]:  # Show first 2\n",
    "            print(f\"      - {doc.source}: {doc.content[:60]}...\")\n",
    "    print(f\"  âœ“ Decision: {step.decision}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "âœ… Every RAG decision is traceable:\n",
    "   â€¢ Query analysis: What information do we need?\n",
    "   â€¢ Retrieval: What documents were found?\n",
    "   â€¢ Selection: Which documents are relevant?\n",
    "   â€¢ Synthesis: How was the answer generated?\n",
    "\n",
    "âœ… Evidence is stored in state:\n",
    "   â€¢ We can verify which documents were used\n",
    "   â€¢ We can check relevance scores\n",
    "   â€¢ We can trace answer back to sources\n",
    "\n",
    "âœ… No hallucination possible:\n",
    "   â€¢ Answer MUST reference actual documents\n",
    "   â€¢ Documents MUST exist in state\n",
    "   â€¢ Validation ensures evidence-before-conclusion\n",
    "\n",
    "This is production-ready RAG reasoning.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2686c66",
   "metadata": {},
   "source": [
    "## ğŸ¯ Key Takeaway: Section 6\n",
    "\n",
    "> **RAG agents must externalize every reasoning decision: query analysis, retrieval, evidence selection, and synthesis. By storing documents and reasoning in state, we prevent hallucination and ensure every answer is grounded in verifiable evidence.**\n",
    "\n",
    "---\n",
    "\n",
    "# Summary: Sections 4-6\n",
    "\n",
    "| Section | Key Implementation |\n",
    "|---------|-------------------|\n",
    "| **Section 4** | Single-agent reasoning with explicit thought/action/observation in state |\n",
    "| **Section 5** | Validation framework to detect skipped steps and hallucinations |\n",
    "| **Section 6** | RAG agent with evidence-based reasoning and validation |\n",
    "\n",
    "---\n",
    "\n",
    "**Next sections (7-10) will cover:**\n",
    "- Visual reasoning flows\n",
    "- Multi-agent reasoning coordination\n",
    "- Common reasoning mistakes\n",
    "- Production reasoning framework\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f991c",
   "metadata": {},
   "source": [
    "<a id=\"section-7\"></a>\n",
    "# Section 7: Visual Diagrams of Reasoning Flow\n",
    "\n",
    "Visual diagrams help us understand how reasoning flows through an agent system.\n",
    "\n",
    "---\n",
    "\n",
    "## 7.1 The Basic Reasoning Loop\n",
    "\n",
    "This is the fundamental pattern all agents follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1eb5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"DIAGRAM 1: Basic Reasoning Loop\")\n",
    "\n",
    "diagram_1 = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚          AGENT REASONING LOOP                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚  START       â”‚\n",
    "              â”‚  (Goal Set)  â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                     â”‚\n",
    "                     â–¼\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚   READ CURRENT STATE  â”‚\n",
    "         â”‚   - What do I know?   â”‚\n",
    "         â”‚   - What's happened?  â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                     â”‚\n",
    "                     â–¼\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚   ğŸ’­ THOUGHT          â”‚\n",
    "         â”‚   - What should I do? â”‚\n",
    "         â”‚   - Why this action?  â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                     â”‚\n",
    "                     â–¼\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚   ğŸ”§ ACTION           â”‚\n",
    "         â”‚   - Execute tool      â”‚\n",
    "         â”‚   - Call API          â”‚\n",
    "         â”‚   - Generate text     â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                     â”‚\n",
    "                     â–¼\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚   ğŸ‘ï¸ OBSERVATION      â”‚\n",
    "         â”‚   - What happened?    â”‚\n",
    "         â”‚   - New information   â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                     â”‚\n",
    "                     â–¼\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚   UPDATE STATE        â”‚\n",
    "         â”‚   - Store observation â”‚\n",
    "         â”‚   - Record reasoning  â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                     â”‚\n",
    "                     â–¼\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚  Goal Done?  â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                     â”‚\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚                 â”‚\n",
    "           NO                YES\n",
    "            â”‚                 â”‚\n",
    "            â”‚                 â–¼\n",
    "            â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚         â”‚  TERMINATE   â”‚\n",
    "            â”‚         â”‚  Return Resultâ”‚\n",
    "            â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "            â”‚\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                      â”‚\n",
    "                      â–¼\n",
    "              [LOOP BACK TO READ STATE]\n",
    "\"\"\"\n",
    "\n",
    "print(diagram_1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "âœ“ Reasoning is ITERATIVE, not one-shot\n",
    "âœ“ Each cycle adds to state\n",
    "âœ“ Observations feed into next thought\n",
    "âœ“ Loop continues until goal is met\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c1f97",
   "metadata": {},
   "source": [
    "## 7.2 Thought â†’ Action â†’ Observation (ReAct Pattern)\n",
    "\n",
    "The core reasoning cycle in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"DIAGRAM 2: Thought â†’ Action â†’ Observation\")\n",
    "\n",
    "diagram_2 = \"\"\"\n",
    "ReAct PATTERN: Reasoning + Acting\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                       ITERATION 1                           â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                             â”‚\n",
    "â”‚  ğŸ’­ THOUGHT:                                                â”‚\n",
    "â”‚     \"I need to find information about X\"                    â”‚\n",
    "â”‚     \"The best way is to search the database\"                â”‚\n",
    "â”‚     â†“                                                       â”‚\n",
    "â”‚  ğŸ”§ ACTION:                                                 â”‚\n",
    "â”‚     search_database(query=\"X\")                              â”‚\n",
    "â”‚     â†“                                                       â”‚\n",
    "â”‚  ğŸ‘ï¸ OBSERVATION:                                            â”‚\n",
    "â”‚     \"Found 5 results: [...]\"                                â”‚\n",
    "â”‚     â†“                                                       â”‚\n",
    "â”‚  ğŸ“ STATE UPDATE:                                           â”‚\n",
    "â”‚     state.search_results = [5 items]                        â”‚\n",
    "â”‚                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â”‚\n",
    "                            â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                       ITERATION 2                           â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                             â”‚\n",
    "â”‚  ğŸ’­ THOUGHT:                                                â”‚\n",
    "â”‚     \"I have 5 results, but which is most relevant?\"         â”‚\n",
    "â”‚     \"I should rank them by score\"                           â”‚\n",
    "â”‚     â†“                                                       â”‚\n",
    "â”‚  ğŸ”§ ACTION:                                                 â”‚\n",
    "â”‚     rank_results(results=state.search_results)              â”‚\n",
    "â”‚     â†“                                                       â”‚\n",
    "â”‚  ğŸ‘ï¸ OBSERVATION:                                            â”‚\n",
    "â”‚     \"Top result has score 0.95\"                             â”‚\n",
    "â”‚     â†“                                                       â”‚\n",
    "â”‚  ğŸ“ STATE UPDATE:                                           â”‚\n",
    "â”‚     state.selected_result = top_result                      â”‚\n",
    "â”‚                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â”‚\n",
    "                            â–¼\n",
    "                          [...]\n",
    "\"\"\"\n",
    "\n",
    "print(diagram_2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "âœ“ Each iteration is self-contained\n",
    "âœ“ Observations from iteration N inform thought in iteration N+1\n",
    "âœ“ State grows with each cycle\n",
    "âœ“ Reasoning is grounded in actual observations, not assumptions\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f3a73",
   "metadata": {},
   "source": [
    "## 7.3 Reasoning vs State Interaction\n",
    "\n",
    "How reasoning artifacts flow into and out of state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d39716",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"DIAGRAM 3: Reasoning â†” State Interaction\")\n",
    "\n",
    "diagram_3 = \"\"\"\n",
    "REASONING AND STATE: A Two-Way Flow\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      AGENT STATE                            â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚\n",
    "â”‚  â”‚  Data Fields:                                   â”‚       â”‚\n",
    "â”‚  â”‚  â€¢ goal: \"Find papers on transformers\"          â”‚       â”‚\n",
    "â”‚  â”‚  â€¢ papers_found: [...]                          â”‚       â”‚\n",
    "â”‚  â”‚  â€¢ selected_papers: [...]                       â”‚       â”‚\n",
    "â”‚  â”‚  â€¢ final_summary: None                          â”‚       â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚\n",
    "â”‚  â”‚  Reasoning Artifacts:                           â”‚       â”‚\n",
    "â”‚  â”‚  â€¢ reasoning_trace: [                           â”‚       â”‚\n",
    "â”‚  â”‚      {thought: \"...\", action: \"...\", obs: \"...\"}â”‚       â”‚\n",
    "â”‚  â”‚      {thought: \"...\", action: \"...\", obs: \"...\"}â”‚       â”‚\n",
    "â”‚  â”‚    ]                                            â”‚       â”‚\n",
    "â”‚  â”‚  â€¢ current_step: 3                              â”‚       â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚\n",
    "â”‚                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â”‚                          â”‚\n",
    "               â”‚ READ                     â”‚ WRITE\n",
    "               â”‚ (Input to reasoning)     â”‚ (Output from reasoning)\n",
    "               â”‚                          â”‚\n",
    "               â–¼                          â–²\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚    REASONING ENGINE                 â”‚\n",
    "         â”‚                                     â”‚\n",
    "         â”‚  Reads:                             â”‚\n",
    "         â”‚  â€¢ Current state data               â”‚\n",
    "         â”‚  â€¢ Previous reasoning steps         â”‚\n",
    "         â”‚  â€¢ Observations from last action    â”‚\n",
    "         â”‚                                     â”‚\n",
    "         â”‚  Decides:                           â”‚\n",
    "         â”‚  â€¢ What to do next                  â”‚\n",
    "         â”‚  â€¢ Which action to take             â”‚\n",
    "         â”‚                                     â”‚\n",
    "         â”‚  Writes:                            â”‚\n",
    "         â”‚  â€¢ New reasoning step               â”‚\n",
    "         â”‚  â€¢ Action results                   â”‚\n",
    "         â”‚  â€¢ Updated data fields              â”‚\n",
    "         â”‚                                     â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "FLOW:\n",
    "1. Reasoning reads current state\n",
    "2. Reasoning decides on action\n",
    "3. Action executes (external world interaction)\n",
    "4. Observation recorded\n",
    "5. State updated with new data + reasoning artifact\n",
    "6. Loop repeats\n",
    "\"\"\"\n",
    "\n",
    "print(diagram_3)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "âœ“ State is both INPUT and OUTPUT of reasoning\n",
    "âœ“ Reasoning artifacts are stored IN state (not separate)\n",
    "âœ“ Each iteration enriches state with:\n",
    "  - New data (observations, results)\n",
    "  - New reasoning (thoughts, decisions)\n",
    "âœ“ This creates an auditable trail\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7936092c",
   "metadata": {},
   "source": [
    "## 7.4 Single-Agent vs Multi-Agent Reasoning\n",
    "\n",
    "Comparing reasoning patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46219e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"DIAGRAM 4: Single-Agent vs Multi-Agent Reasoning\")\n",
    "\n",
    "diagram_4 = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚               SINGLE-AGENT REASONING                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "    State\n",
    "      â”‚\n",
    "      â–¼\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”‚ Agent   â”‚\n",
    "  â”‚ Thinks  â”‚â”€â”€â†’ Action â”€â”€â†’ Observation\n",
    "  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                    â”‚\n",
    "       â”‚                         â”‚\n",
    "       â””â”€â”€â”€â”€â”€ Update State â—„â”€â”€â”€â”€â”€â”˜\n",
    "                â”‚\n",
    "                â–¼\n",
    "              [Repeat]\n",
    "\n",
    "â€¢ Single reasoning loop\n",
    "â€¢ One perspective\n",
    "â€¢ Linear progression\n",
    "\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚              MULTI-AGENT REASONING                          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "         Shared State\n",
    "              â”‚\n",
    "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”\n",
    "      â”‚               â”‚\n",
    "      â–¼               â–¼\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”‚Agent A  â”‚    â”‚Agent B  â”‚\n",
    "  â”‚(Critic) â”‚    â”‚(Writer) â”‚\n",
    "  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜\n",
    "       â”‚              â”‚\n",
    "       â”‚ Reasoning A  â”‚ Reasoning B\n",
    "       â”‚              â”‚\n",
    "       â–¼              â–¼\n",
    "   Action A       Action B\n",
    "       â”‚              â”‚\n",
    "       â–¼              â–¼\n",
    "  Obs A           Obs B\n",
    "       â”‚              â”‚\n",
    "       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "              â”‚\n",
    "              â–¼\n",
    "      Update Shared State\n",
    "       (both reasoning traces)\n",
    "              â”‚\n",
    "              â–¼\n",
    "           [Repeat]\n",
    "\n",
    "â€¢ Multiple reasoning loops\n",
    "â€¢ Different perspectives\n",
    "â€¢ Potential conflicts\n",
    "â€¢ Need for coordination\n",
    "\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚          KEY DIFFERENCE: REASONING CONTRACTS                â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Single-Agent:\n",
    "  â€¢ Agent owns all reasoning\n",
    "  â€¢ No conflicts possible\n",
    "  â€¢ Simple validation\n",
    "\n",
    "Multi-Agent:\n",
    "  â€¢ Must share reasoning artifacts\n",
    "  â€¢ Can have contradictions\n",
    "  â€¢ Requires reasoning alignment checks\n",
    "  â€¢ Need handoff protocols\n",
    "\"\"\"\n",
    "\n",
    "print(diagram_4)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "âœ“ Multi-agent systems need REASONING CONTRACTS:\n",
    "  - What reasoning does each agent contribute?\n",
    "  - How do agents hand off work?\n",
    "  - How are contradictions resolved?\n",
    "\n",
    "âœ“ Without shared reasoning artifacts:\n",
    "  - Agent B can't understand why Agent A did something\n",
    "  - Debugging multi-agent failures is impossible\n",
    "  - Coordination breaks down\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc485e5f",
   "metadata": {},
   "source": [
    "## ğŸ¯ Key Takeaway: Section 7\n",
    "\n",
    "> **Visual diagrams reveal the structure of reasoning: it's an iterative loop where thought, action, and observation flow into state, creating an auditable trail. Multi-agent systems require reasoning contracts to coordinate perspectives and avoid conflicts.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8452d",
   "metadata": {},
   "source": [
    "<a id=\"section-8\"></a>\n",
    "# Section 8: Reasoning in Multi-Agent Systems (MAS)\n",
    "\n",
    "Multi-agent systems require explicit reasoning coordination.\n",
    "\n",
    "---\n",
    "\n",
    "## 8.1 Why MAS Needs Reasoning Contracts\n",
    "\n",
    "In multi-agent systems, agents must:\n",
    "- **Share reasoning context**: Agent B needs to understand why Agent A made a decision\n",
    "- **Coordinate work**: Avoid duplicate effort or contradictory actions\n",
    "- **Resolve conflicts**: When agents disagree, reasoning explains why\n",
    "\n",
    "**Without reasoning contracts:**\n",
    "- âŒ Agents work in silos\n",
    "- âŒ Contradictions go undetected\n",
    "- âŒ Debugging is impossible\n",
    "- âŒ Coordination breaks down\n",
    "\n",
    "---\n",
    "\n",
    "## 8.2 Multi-Agent State Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad61683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AgentReasoningEntry:\n",
    "    \"\"\"Reasoning from a specific agent\"\"\"\n",
    "    agent_name: str\n",
    "    step_number: int\n",
    "    thought: str\n",
    "    action: str\n",
    "    observation: str\n",
    "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "\n",
    "@dataclass\n",
    "class MultiAgentState:\n",
    "    \"\"\"Shared state for multiple agents\"\"\"\n",
    "    goal: str\n",
    "    current_agent: Optional[str] = None\n",
    "    reasoning_history: List[AgentReasoningEntry] = field(default_factory=list)\n",
    "    draft_content: Optional[str] = None\n",
    "    critique: Optional[str] = None\n",
    "    final_content: Optional[str] = None\n",
    "    is_complete: bool = False\n",
    "    \n",
    "    def add_agent_reasoning(self, agent_name: str, thought: str, action: str, observation: str):\n",
    "        \"\"\"Add reasoning from a specific agent\"\"\"\n",
    "        entry = AgentReasoningEntry(\n",
    "            agent_name=agent_name,\n",
    "            step_number=len(self.reasoning_history) + 1,\n",
    "            thought=thought,\n",
    "            action=action,\n",
    "            observation=observation\n",
    "        )\n",
    "        self.reasoning_history.append(entry)\n",
    "        self.current_agent = agent_name\n",
    "        return entry\n",
    "    \n",
    "    def get_reasoning_by_agent(self, agent_name: str) -> List[AgentReasoningEntry]:\n",
    "        \"\"\"Get all reasoning from a specific agent\"\"\"\n",
    "        return [r for r in self.reasoning_history if r.agent_name == agent_name]\n",
    "\n",
    "print(\"âœ“ Multi-agent state schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403be47f",
   "metadata": {},
   "source": [
    "## 8.3 Implementing Writer-Critic Multi-Agent System\n",
    "\n",
    "Two agents with different reasoning roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writer_agent(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"Agent that writes content\"\"\"\n",
    "    # THOUGHT: What's my role?\n",
    "    thought = f\"My goal is to write content about: {state.goal}. I will create a draft.\"\n",
    "    \n",
    "    # ACTION: Generate draft\n",
    "    action = \"write_draft\"\n",
    "    draft = f\"Draft content about {state.goal}: Transformers revolutionized NLP by introducing self-attention mechanisms...\"\n",
    "    \n",
    "    # OBSERVATION: What did I produce?\n",
    "    observation = f\"Created draft with {len(draft)} characters\"\n",
    "    \n",
    "    # Record reasoning\n",
    "    state.add_agent_reasoning(\"Writer\", thought, action, observation)\n",
    "    state.draft_content = draft\n",
    "    \n",
    "    return state\n",
    "\n",
    "def critic_agent(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"Agent that critiques content\"\"\"\n",
    "    # THOUGHT: What's my role?\n",
    "    thought = f\"I need to review the Writer's draft and provide constructive feedback.\"\n",
    "    \n",
    "    # Check if draft exists\n",
    "    if not state.draft_content:\n",
    "        observation = \"ERROR: No draft to critique\"\n",
    "        state.add_agent_reasoning(\"Critic\", thought, \"check_draft\", observation)\n",
    "        return state\n",
    "    \n",
    "    # ACTION: Critique the draft\n",
    "    action = \"critique_draft\"\n",
    "    \n",
    "    # Analyze the draft\n",
    "    draft_length = len(state.draft_content)\n",
    "    has_specific_details = \"self-attention\" in state.draft_content.lower()\n",
    "    \n",
    "    if draft_length < 50:\n",
    "        critique = \"FEEDBACK: Draft is too short. Add more details.\"\n",
    "    elif not has_specific_details:\n",
    "        critique = \"FEEDBACK: Draft lacks technical depth. Add specifics about mechanisms.\"\n",
    "    else:\n",
    "        critique = \"FEEDBACK: Draft looks good. Could add examples for clarity.\"\n",
    "    \n",
    "    # OBSERVATION: What's my verdict?\n",
    "    observation = f\"Critique completed: {critique}\"\n",
    "    \n",
    "    # Record reasoning\n",
    "    state.add_agent_reasoning(\"Critic\", thought, action, observation)\n",
    "    state.critique = critique\n",
    "    \n",
    "    return state\n",
    "\n",
    "def writer_revise(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"Writer revises based on critique\"\"\"\n",
    "    # THOUGHT: What did the Critic say?\n",
    "    thought = f\"The Critic said: '{state.critique}'. I will revise accordingly.\"\n",
    "    \n",
    "    # ACTION: Revise draft\n",
    "    action = \"revise_draft\"\n",
    "    \n",
    "    # Incorporate feedback\n",
    "    if \"examples\" in state.critique.lower():\n",
    "        revised = state.draft_content + \" For example, BERT uses bidirectional attention for context understanding.\"\n",
    "    else:\n",
    "        revised = state.draft_content + \" (Revised based on feedback)\"\n",
    "    \n",
    "    # OBSERVATION: What's the result?\n",
    "    observation = \"Revision complete\"\n",
    "    \n",
    "    # Record reasoning\n",
    "    state.add_agent_reasoning(\"Writer\", thought, action, observation)\n",
    "    state.final_content = revised\n",
    "    state.is_complete = True\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"âœ“ Multi-agent functions defined (Writer, Critic, Writer-Revise)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d9359",
   "metadata": {},
   "source": [
    "## 8.4 Running the Multi-Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5955e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"MULTI-AGENT SYSTEM EXECUTION\")\n",
    "\n",
    "# Initialize shared state\n",
    "mas_state = MultiAgentState(goal=\"Explain transformers\")\n",
    "\n",
    "print(f\"Goal: {mas_state.goal}\\n\")\n",
    "\n",
    "# Step 1: Writer creates draft\n",
    "print(\"â–¶ Step 1: Writer Agent\")\n",
    "mas_state = writer_agent(mas_state)\n",
    "latest = mas_state.reasoning_history[-1]\n",
    "print(f\"  Agent: {latest.agent_name}\")\n",
    "print(f\"  Thought: {latest.thought}\")\n",
    "print(f\"  Action: {latest.action}\")\n",
    "print(f\"  Observation: {latest.observation}\")\n",
    "print(f\"  Output: Draft created ({len(mas_state.draft_content)} chars)\")\n",
    "\n",
    "# Step 2: Critic reviews draft\n",
    "print(\"\\nâ–¶ Step 2: Critic Agent\")\n",
    "mas_state = critic_agent(mas_state)\n",
    "latest = mas_state.reasoning_history[-1]\n",
    "print(f\"  Agent: {latest.agent_name}\")\n",
    "print(f\"  Thought: {latest.thought}\")\n",
    "print(f\"  Action: {latest.action}\")\n",
    "print(f\"  Observation: {latest.observation}\")\n",
    "print(f\"  Critique: {mas_state.critique}\")\n",
    "\n",
    "# Step 3: Writer revises based on critique\n",
    "print(\"\\nâ–¶ Step 3: Writer Revises\")\n",
    "mas_state = writer_revise(mas_state)\n",
    "latest = mas_state.reasoning_history[-1]\n",
    "print(f\"  Agent: {latest.agent_name}\")\n",
    "print(f\"  Thought: {latest.thought}\")\n",
    "print(f\"  Action: {latest.action}\")\n",
    "print(f\"  Observation: {latest.observation}\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"FINAL RESULT\")\n",
    "print('=' * 60)\n",
    "print(f\"Complete: {mas_state.is_complete}\")\n",
    "print(f\"Final content: {mas_state.final_content}\")\n",
    "print(f\"\\nTotal reasoning steps: {len(mas_state.reasoning_history)}\")\n",
    "print(f\"Writer steps: {len(mas_state.get_reasoning_by_agent('Writer'))}\")\n",
    "print(f\"Critic steps: {len(mas_state.get_reasoning_by_agent('Critic'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26efaeb",
   "metadata": {},
   "source": [
    "## 8.5 Validating Multi-Agent Reasoning\n",
    "\n",
    "Check for reasoning alignment and detect contradictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd53c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mas_reasoning_alignment(state: MultiAgentState) -> bool:\n",
    "    \"\"\"Validate that agents worked together coherently\"\"\"\n",
    "    \n",
    "    # Check 1: Writer created draft before Critic reviewed\n",
    "    writer_steps = state.get_reasoning_by_agent(\"Writer\")\n",
    "    critic_steps = state.get_reasoning_by_agent(\"Critic\")\n",
    "    \n",
    "    if critic_steps and not writer_steps:\n",
    "        raise ReasoningValidationError(\n",
    "            \"Critic acted without Writer creating content first\"\n",
    "        )\n",
    "    \n",
    "    if critic_steps:\n",
    "        first_critic_step = min(c.step_number for c in critic_steps)\n",
    "        first_writer_step = min(w.step_number for w in writer_steps)\n",
    "        if first_critic_step < first_writer_step:\n",
    "            raise ReasoningValidationError(\n",
    "                \"Critic acted before Writer (ordering violation)\"\n",
    "            )\n",
    "    \n",
    "    print(\"âœ“ Agent ordering validated: Writer â†’ Critic â†’ Writer\")\n",
    "    \n",
    "    # Check 2: Critique was actually used\n",
    "    if state.critique and len(writer_steps) > 1:\n",
    "        revision_step = writer_steps[-1]\n",
    "        if state.critique not in revision_step.thought:\n",
    "            raise ReasoningValidationError(\n",
    "                \"Writer revision doesn't reference Critic's feedback\"\n",
    "            )\n",
    "    print(\"âœ“ Reasoning handoff validated: Writer acknowledged Critic's feedback\")\n",
    "    \n",
    "    # Check 3: No contradictions in reasoning\n",
    "    for entry in state.reasoning_history:\n",
    "        if \"ERROR\" in entry.observation and state.is_complete:\n",
    "            raise ReasoningValidationError(\n",
    "                f\"Agent {entry.agent_name} encountered error but system marked complete\"\n",
    "            )\n",
    "    print(\"âœ“ No contradictions detected in reasoning history\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def validate_mas_no_contradictions(state: MultiAgentState) -> bool:\n",
    "    \"\"\"Check for logical contradictions between agents\"\"\"\n",
    "    \n",
    "    # Example: If Critic says \"too short\" but Writer says \"looks complete\"\n",
    "    critic_feedback = state.critique if state.critique else \"\"\n",
    "    \n",
    "    if \"too short\" in critic_feedback.lower() and state.is_complete:\n",
    "        # Check if Writer actually addressed this\n",
    "        writer_revisions = [r for r in state.reasoning_history \n",
    "                           if r.agent_name == \"Writer\" and \"revise\" in r.action.lower()]\n",
    "        if not writer_revisions:\n",
    "            raise ReasoningValidationError(\n",
    "                \"Critic said content too short, but Writer didn't revise\"\n",
    "            )\n",
    "    \n",
    "    print(\"âœ“ No logical contradictions between agents\")\n",
    "    return True\n",
    "\n",
    "print_section_header(\"VALIDATING MULTI-AGENT REASONING\")\n",
    "\n",
    "try:\n",
    "    validate_mas_reasoning_alignment(mas_state)\n",
    "    validate_mas_no_contradictions(mas_state)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âœ… MULTI-AGENT REASONING VALIDATED\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"The agents:\")\n",
    "    print(\"  â€¢ Worked in proper order\")\n",
    "    print(\"  â€¢ Shared reasoning context\")\n",
    "    print(\"  â€¢ No contradictions detected\")\n",
    "    print(\"  â€¢ Proper handoff of work\")\n",
    "    \n",
    "except ReasoningValidationError as e:\n",
    "    print(f\"\\nâŒ VALIDATION FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649301ca",
   "metadata": {},
   "source": [
    "## 8.6 Failure Mode: No Shared Reasoning\n",
    "\n",
    "What happens without shared reasoning artifacts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"FAILURE MODE: Isolated Agent Reasoning\")\n",
    "\n",
    "# Create broken MAS where agents don't share reasoning\n",
    "broken_mas = MultiAgentState(goal=\"Write article\")\n",
    "\n",
    "# Writer works in isolation (no reasoning recorded)\n",
    "broken_mas.draft_content = \"Some content...\"\n",
    "# Note: NO reasoning added to state\n",
    "\n",
    "# Critic works in isolation (no reasoning recorded)\n",
    "broken_mas.critique = \"Needs work\"\n",
    "# Note: NO reasoning added to state\n",
    "\n",
    "# Final content appears (no reasoning about revision)\n",
    "broken_mas.final_content = \"Different content...\"\n",
    "broken_mas.is_complete = True\n",
    "\n",
    "print(\"Broken MAS created (no shared reasoning)\")\n",
    "print(f\"Draft: {broken_mas.draft_content}\")\n",
    "print(f\"Critique: {broken_mas.critique}\")\n",
    "print(f\"Final: {broken_mas.final_content}\")\n",
    "print(f\"Reasoning history: {len(broken_mas.reasoning_history)} entries\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Attempting validation...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "try:\n",
    "    validate_mas_reasoning_alignment(broken_mas)\n",
    "    print(\"âœ… Validation passed (this should NOT happen)\")\n",
    "except ReasoningValidationError as e:\n",
    "    print(f\"âŒ Validation caught the error!\")\n",
    "    print(f\"   Error: {e}\")\n",
    "    print(\"\\nâœ“ This is GOOD - validation detected missing reasoning\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WHY THIS FAILS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "Without shared reasoning artifacts:\n",
    "\n",
    "âŒ Can't verify Writer created draft before Critic reviewed\n",
    "âŒ Can't verify Critic actually reviewed the draft\n",
    "âŒ Can't verify Writer used Critic's feedback\n",
    "âŒ Can't debug coordination issues\n",
    "âŒ Can't audit the decision-making process\n",
    "\n",
    "This is why reasoning contracts are critical in MAS.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c78da4c",
   "metadata": {},
   "source": [
    "## ğŸ¯ Key Takeaway: Section 8\n",
    "\n",
    "> **Multi-agent systems require reasoning contracts: shared state where each agent records its thoughts, actions, and observations. Without explicit reasoning handoffs, agents work in silos, contradictions go undetected, and coordination breaks down.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba1524",
   "metadata": {},
   "source": [
    "<a id=\"section-9\"></a>\n",
    "# Section 9: Common Reasoning Failures\n",
    "\n",
    "Let's examine the most common mistakes in agent reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "## 9.1 Failure Mode 1: Prompt-Only Reasoning\n",
    "\n",
    "**The Mistake:** Putting all reasoning in the prompt and hoping the LLM will \"just do it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"FAILURE 1: Prompt-Only Reasoning\")\n",
    "\n",
    "# BAD: All reasoning in prompt\n",
    "bad_prompt = \"\"\"\n",
    "You are a research agent. \n",
    "1. Search for papers on transformers\n",
    "2. Filter to the top 3 by citations\n",
    "3. Read their abstracts\n",
    "4. Synthesize a summary\n",
    "\n",
    "Please complete this task.\n",
    "\"\"\"\n",
    "\n",
    "print(\"âŒ BAD APPROACH:\")\n",
    "print(bad_prompt)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"What happens:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "â€¢ LLM generates text that LOOKS like it did those steps\n",
    "â€¢ But no actual search occurred\n",
    "â€¢ No actual papers were retrieved\n",
    "â€¢ Summary is hallucinated\n",
    "â€¢ No way to verify any step\n",
    "\n",
    "Result: \"Based on recent papers, transformers use attention...\"\n",
    "  â†‘ This is made up!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"WHY THIS FAILS:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "1. No actual tool calls (search didn't happen)\n",
    "2. No state tracking (can't verify papers exist)\n",
    "3. No observable reasoning (can't debug)\n",
    "4. No validation possible (no evidence to check)\n",
    "\n",
    "The LLM generates plausible text, but does no actual work.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dadb088",
   "metadata": {},
   "source": [
    "## 9.2 Failure Mode 2: Hidden Chain-of-Thought\n",
    "\n",
    "**The Mistake:** Using chain-of-thought prompting but not externalizing reasoning into state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4915e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"FAILURE 2: Hidden Chain-of-Thought\")\n",
    "\n",
    "# BAD: Chain-of-thought in response text\n",
    "simulated_response = \"\"\"\n",
    "Let me think step by step:\n",
    "\n",
    "Step 1: I would search for papers on transformers\n",
    "Step 2: I would filter by citation count\n",
    "Step 3: I would read the top papers\n",
    "Step 4: Based on my analysis, transformers work by...\n",
    "\n",
    "Final answer: Transformers use self-attention mechanisms.\n",
    "\"\"\"\n",
    "\n",
    "print(\"âŒ BAD APPROACH:\")\n",
    "print(simulated_response)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"What's in state after this:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "state = {\n",
    "    \"response\": \"Let me think step by step:...\"\n",
    "}\n",
    "\n",
    "That's it. The \"reasoning\" is just unstructured text.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"WHY THIS FAILS:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "1. Reasoning is in TEXT, not STRUCTURED STATE\n",
    "   â†’ Can't programmatically validate steps\n",
    "   \n",
    "2. Can't branch based on intermediate results\n",
    "   â†’ \"If step 2 finds <5 papers, do X else Y\" is impossible\n",
    "   \n",
    "3. Can't extract intermediate values\n",
    "   â†’ Can't access the \"list of papers\" for further processing\n",
    "   \n",
    "4. Can't call tools between steps\n",
    "   â†’ All \"steps\" are simulated, not actual actions\n",
    "   \n",
    "5. Reasoning and data are mixed\n",
    "   â†’ Can't separate \"what was decided\" from \"what was found\"\n",
    "\n",
    "The reasoning LOOKS explicit, but it's still hidden in text.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9942c08",
   "metadata": {},
   "source": [
    "## 9.3 Failure Mode 3: Over-Trusting LLM \"Confidence\"\n",
    "\n",
    "**The Mistake:** Assuming that confident-sounding responses are accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c274a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"FAILURE 3: Over-Trusting LLM Confidence\")\n",
    "\n",
    "# Simulated confident but wrong LLM response\n",
    "confident_hallucination = \"\"\"\n",
    "Based on my comprehensive analysis of recent literature,\n",
    "I can confidently state that transformers were invented\n",
    "in 2019 by researchers at OpenAI. The architecture uses\n",
    "a novel \"circular attention\" mechanism that processes\n",
    "sequences in both forward and backward directions \n",
    "simultaneously, achieving 99.8% accuracy on all NLP tasks.\n",
    "\n",
    "Sources:\n",
    "- \"Transformers Unleashed\" (Smith et al., 2019)\n",
    "- \"The Circular Attention Paper\" (Jones, 2020)\n",
    "\"\"\"\n",
    "\n",
    "print(\"âŒ LLM Response (sounds confident!):\")\n",
    "print(confident_hallucination)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"What's ACTUALLY true:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "âœ— Transformers were invented in 2017, not 2019\n",
    "âœ— By Google (Vaswani et al.), not OpenAI\n",
    "âœ— \"Circular attention\" doesn't exist (made up)\n",
    "âœ— Those papers don't exist (hallucinated citations)\n",
    "âœ— 99.8% accuracy on all tasks is absurd\n",
    "\n",
    "But it SOUNDS authoritative!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"WHY THIS FAILS:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "1. LLMs generate confident-sounding text even when wrong\n",
    "   â†’ Confidence â‰  Accuracy\n",
    "   \n",
    "2. No source verification\n",
    "   â†’ Can't check if cited papers exist\n",
    "   \n",
    "3. No grounding in evidence\n",
    "   â†’ No actual papers retrieved from database\n",
    "   \n",
    "4. No validation layer\n",
    "   â†’ No fact-checking against known sources\n",
    "\n",
    "FIX: Never trust LLM output without validation\n",
    "     Always require evidence from state (retrieved docs, API calls, etc.)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86376aaa",
   "metadata": {},
   "source": [
    "## 9.4 Failure Mode 4: Reasoning Not Grounded in Evidence\n",
    "\n",
    "**The Mistake:** Making inferences or conclusions without retrievable evidence in state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2212e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"FAILURE 4: Reasoning Without Evidence\")\n",
    "\n",
    "# Simulated state with conclusion but no evidence\n",
    "ungrounded_state = {\n",
    "    \"goal\": \"Analyze transformer performance\",\n",
    "    \"reasoning\": \"Based on extensive analysis...\",\n",
    "    \"conclusion\": \"Transformers outperform RNNs by 40% on all tasks\",\n",
    "    # NOTE: No evidence!\n",
    "    \"papers_retrieved\": [],  # Empty!\n",
    "    \"benchmarks_run\": [],    # Empty!\n",
    "    \"data_analyzed\": None    # None!\n",
    "}\n",
    "\n",
    "print(\"âŒ BAD STATE:\")\n",
    "pprint(ungrounded_state)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"The Problem:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "The agent claims \"transformers outperform RNNs by 40%\"\n",
    "\n",
    "But where's the evidence?\n",
    "âœ— No papers in state\n",
    "âœ— No benchmarks in state\n",
    "âœ— No data in state\n",
    "\n",
    "The conclusion is ungrounded - it's a hallucination.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"WHY THIS FAILS:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "1. Conclusion without evidence\n",
    "   â†’ Can't verify the 40% claim\n",
    "   \n",
    "2. No traceable reasoning path\n",
    "   â†’ Can't see how conclusion was reached\n",
    "   \n",
    "3. Can't audit the analysis\n",
    "   â†’ No raw data to check\n",
    "   \n",
    "4. Can't reproduce the result\n",
    "   â†’ Missing all inputs\n",
    "\n",
    "FIX: Every conclusion MUST reference evidence in state\n",
    "     Validation should check: evidence exists â†’ conclusion drawn\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"CORRECT APPROACH:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "grounded_state = {\n",
    "    \"goal\": \"Analyze transformer performance\",\n",
    "    \"papers_retrieved\": [\n",
    "        {\"title\": \"Paper A\", \"result\": \"35% improvement\"},\n",
    "        {\"title\": \"Paper B\", \"result\": \"42% improvement\"}\n",
    "    ],\n",
    "    \"reasoning\": \"Averaging results from Paper A (35%) and Paper B (42%)\",\n",
    "    \"conclusion\": \"Transformers outperform RNNs by ~38.5% based on 2 studies\"\n",
    "}\n",
    "\n",
    "print(\"âœ… GOOD STATE:\")\n",
    "pprint(grounded_state)\n",
    "print(\"\\nNow we can:\")\n",
    "print(\"âœ“ Verify the papers exist\")\n",
    "print(\"âœ“ Check the math (35+42)/2 = 38.5\")\n",
    "print(\"âœ“ Trace reasoning from evidence to conclusion\")\n",
    "print(\"âœ“ Audit the quality of sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0211a0d3",
   "metadata": {},
   "source": [
    "## 9.5 Summary of Common Failures\n",
    "\n",
    "| Failure Mode | Symptom | Fix |\n",
    "|--------------|---------|-----|\n",
    "| **Prompt-Only** | No actual work done, just text | Implement actual tool calls + state |\n",
    "| **Hidden CoT** | Reasoning in text, not structure | Externalize to typed state fields |\n",
    "| **Over-Trust** | Confident hallucinations | Always validate against evidence |\n",
    "| **Ungrounded** | Conclusions without evidence | Require evidence â†’ reasoning â†’ conclusion |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Key Takeaway: Section 9\n",
    "\n",
    "> **Common reasoning failures all stem from the same root cause: treating reasoning as text generation instead of as a structured, evidence-based, verifiable process. The fix is always the same: externalize reasoning into state, ground it in evidence, and validate rigorously.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c693fa",
   "metadata": {},
   "source": [
    "<a id=\"section-10\"></a>\n",
    "# Section 10: Final Mental Model & Production Checklist\n",
    "\n",
    "Bringing it all together.\n",
    "\n",
    "---\n",
    "\n",
    "## 10.1 The Complete Mental Model of Agent Reasoning\n",
    "\n",
    "### Core Principles\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚          AGENT REASONING MENTAL MODEL                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "1. REASONING IS A PROCESS, NOT A PROMPT\n",
    "   â€¢ Not: \"LLM, think about this\"\n",
    "   â€¢ Yes: Iterative loop of thought â†’ action â†’ observation\n",
    "\n",
    "2. REASONING MUST BE EXTERNALIZED\n",
    "   â€¢ Not: Hidden in LLM's internal chain-of-thought\n",
    "   â€¢ Yes: Stored in structured state as typed fields\n",
    "\n",
    "3. REASONING MUST BE GROUNDED IN EVIDENCE\n",
    "   â€¢ Not: LLM generates conclusions from memory\n",
    "   â€¢ Yes: Conclusions derived from retrieved evidence in state\n",
    "\n",
    "4. REASONING MUST BE VALIDATABLE\n",
    "   â€¢ Not: Trust the output blindly\n",
    "   â€¢ Yes: Programmatic checks ensure correctness\n",
    "\n",
    "5. REASONING IS STATE EVOLUTION\n",
    "   â€¢ Not: Stateless prompt â†’ response\n",
    "   â€¢ Yes: State grows with each reasoning step\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 10.2 The Three Layers of Agent Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"The Three Layers of Reasoning\")\n",
    "\n",
    "three_layers = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    LAYER 1: DATA                            â”‚\n",
    "â”‚  What the agent knows                                       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  â€¢ Retrieved documents                                      â”‚\n",
    "â”‚  â€¢ API responses                                            â”‚\n",
    "â”‚  â€¢ User inputs                                              â”‚\n",
    "â”‚  â€¢ Calculated results                                       â”‚\n",
    "â”‚  â€¢ Observations from actions                                â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â–²\n",
    "                            â”‚ Feeds into\n",
    "                            â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                  LAYER 2: REASONING                         â”‚\n",
    "â”‚  How the agent decides                                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  â€¢ Thoughts (what to do next)                               â”‚\n",
    "â”‚  â€¢ Decisions (which action to take)                         â”‚\n",
    "â”‚  â€¢ Justifications (why this action)                         â”‚\n",
    "â”‚  â€¢ Reasoning trace (history of decisions)                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â–²\n",
    "                            â”‚ Evaluated by\n",
    "                            â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                 LAYER 3: VALIDATION                         â”‚\n",
    "â”‚  How we verify correctness                                  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  â€¢ Sequence checks (steps in order)                         â”‚\n",
    "â”‚  â€¢ Evidence checks (data exists)                            â”‚\n",
    "â”‚  â€¢ Consistency checks (no contradictions)                   â”‚\n",
    "â”‚  â€¢ Completeness checks (all steps present)                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "KEY INSIGHT:\n",
    "All three layers are STORED IN STATE.\n",
    "You can inspect, debug, and audit all three at any time.\n",
    "\"\"\"\n",
    "\n",
    "print(three_layers)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"What This Means in Practice\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "âŒ DON'T: Mix layers\n",
    "   â€¢ Don't put reasoning in prompts\n",
    "   â€¢ Don't hide data in LLM context\n",
    "   â€¢ Don't skip validation\n",
    "\n",
    "âœ… DO: Separate concerns\n",
    "   â€¢ Data goes in state.data_fields\n",
    "   â€¢ Reasoning goes in state.reasoning_trace\n",
    "   â€¢ Validation checks both layers\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f2caef",
   "metadata": {},
   "source": [
    "## 10.3 Production-Ready Reasoning Checklist\n",
    "\n",
    "Use this checklist when designing or reviewing agent reasoning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f666630",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"PRODUCTION REASONING CHECKLIST\")\n",
    "\n",
    "checklist = \"\"\"\n",
    "â˜‘ï¸ AGENT REASONING DESIGN CHECKLIST\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ARCHITECTURE\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    " â˜  1. Reasoning is externalized into structured state\n",
    " â˜  2. State schema includes reasoning_trace field\n",
    " â˜  3. Each reasoning step has: thought, action, observation\n",
    " â˜  4. Reasoning artifacts are typed (TypedDict/dataclass)\n",
    " â˜  5. Clear separation between data and reasoning\n",
    "\n",
    "ITERATION\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    " â˜  6. Reasoning follows Thought â†’ Action â†’ Observation loop\n",
    " â˜  7. Each iteration updates state (not just returns text)\n",
    " â˜  8. Observations from step N feed into thought for step N+1\n",
    " â˜  9. Clear termination condition (when to stop reasoning)\n",
    " â˜ 10. Maximum iteration limit (prevent infinite loops)\n",
    "\n",
    "EVIDENCE\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    " â˜ 11. All conclusions reference evidence in state\n",
    " â˜ 12. Evidence is retrieved from actual sources (not LLM memory)\n",
    " â˜ 13. Documents/data stored in state, not just cited\n",
    " â˜ 14. Can trace from evidence â†’ reasoning â†’ conclusion\n",
    " â˜ 15. No hallucinated references or data\n",
    "\n",
    "VALIDATION\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    " â˜ 16. Validation functions check reasoning sequence\n",
    " â˜ 17. Verify no steps were skipped\n",
    " â˜ 18. Verify evidence exists before conclusions\n",
    " â˜ 19. Verify observations are non-empty\n",
    " â˜ 20. Automated tests for validation logic\n",
    "\n",
    "DEBUGGING & OBSERVABILITY\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    " â˜ 21. Can print/log complete reasoning trace\n",
    " â˜ 22. Each step has timestamp for debugging\n",
    " â˜ 23. Can replay reasoning for audit\n",
    " â˜ 24. Errors include reasoning context\n",
    " â˜ 25. Monitoring for reasoning quality metrics\n",
    "\n",
    "MULTI-AGENT (if applicable)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    " â˜ 26. Shared state includes agent_name for each step\n",
    " â˜ 27. Clear reasoning contracts between agents\n",
    " â˜ 28. Validation checks for agent coordination\n",
    " â˜ 29. Contradiction detection between agents\n",
    " â˜ 30. Reasoning handoff is explicit in state\n",
    "\n",
    "PRODUCTION SCALING\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    " â˜ 31. Reasoning trace has size limits (prevent memory bloat)\n",
    " â˜ 32. State serialization/deserialization works\n",
    " â˜ 33. Can resume from partial reasoning state\n",
    " â˜ 34. Reasoning steps are idempotent (safe to retry)\n",
    " â˜ 35. Performance metrics: steps per task, time per step\n",
    "\"\"\"\n",
    "\n",
    "print(checklist)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HOW TO USE THIS CHECKLIST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "1. Before implementing: Review checklist, design state schema\n",
    "2. During development: Check off items as you implement\n",
    "3. Before deployment: All items should be âœ“\n",
    "4. In production: Monitor items 31-35 continuously\n",
    "\n",
    "If you can check all boxes, your reasoning is production-ready.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e58353",
   "metadata": {},
   "source": [
    "## 10.4 Scaling Reasoning in Production\n",
    "\n",
    "Practical guidance for production deployments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa04a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(\"SCALING REASONING IN PRODUCTION\")\n",
    "\n",
    "scaling_guide = \"\"\"\n",
    "CHALLENGE 1: REASONING TRACE SIZE\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "Problem: Long-running agents accumulate large reasoning traces\n",
    "Solution:\n",
    "  â€¢ Set max_reasoning_steps limit\n",
    "  â€¢ Implement trace summarization (keep summaries, discard details)\n",
    "  â€¢ Prune intermediate steps after validation passes\n",
    "  â€¢ Store full trace in separate logging system\n",
    "\n",
    "Example:\n",
    "  if len(state.reasoning_trace) > MAX_STEPS:\n",
    "      # Keep first 5, last 10, summarize middle\n",
    "      state.reasoning_trace = (\n",
    "          state.reasoning_trace[:5] + \n",
    "          [summarize(state.reasoning_trace[5:-10])] +\n",
    "          state.reasoning_trace[-10:]\n",
    "      )\n",
    "\n",
    "\n",
    "CHALLENGE 2: VALIDATION OVERHEAD\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "Problem: Running validation after every step is expensive\n",
    "Solution:\n",
    "  â€¢ Validate only at checkpoints (every N steps)\n",
    "  â€¢ Use lightweight checks during iteration\n",
    "  â€¢ Full validation only before final output\n",
    "  â€¢ Cache validation results\n",
    "\n",
    "Example:\n",
    "  if step_num % VALIDATION_INTERVAL == 0:\n",
    "      validate_reasoning_so_far(state)\n",
    "  \n",
    "  # Always validate before returning to user\n",
    "  if is_complete:\n",
    "      full_validation(state)\n",
    "\n",
    "\n",
    "CHALLENGE 3: MULTI-AGENT COORDINATION AT SCALE\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "Problem: Many agents â†’ many reasoning traces â†’ hard to debug\n",
    "Solution:\n",
    "  â€¢ Each agent has clear responsibility contract\n",
    "  â€¢ Reasoning includes agent_id in every step\n",
    "  â€¢ Centralized coordination logic\n",
    "  â€¢ Agent-specific validation rules\n",
    "\n",
    "Example:\n",
    "  state.add_reasoning(\n",
    "      agent_id=\"researcher_42\",\n",
    "      phase=\"search\",\n",
    "      ...\n",
    "  )\n",
    "  \n",
    "  # Can filter: show only researcher_42's reasoning\n",
    "  agent_trace = [s for s in state.reasoning_trace \n",
    "                 if s.agent_id == \"researcher_42\"]\n",
    "\n",
    "\n",
    "CHALLENGE 4: REASONING OBSERVABILITY\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "Problem: Need to monitor reasoning quality in production\n",
    "Solution:\n",
    "  â€¢ Log reasoning metrics: steps_per_task, avg_time_per_step\n",
    "  â€¢ Alert on anomalies: too many steps, stuck loops\n",
    "  â€¢ Sample reasoning traces for human review\n",
    "  â€¢ A/B test different reasoning strategies\n",
    "\n",
    "Metrics to track:\n",
    "  â€¢ Average steps to completion\n",
    "  â€¢ Validation pass rate\n",
    "  â€¢ Evidence retrieval success rate\n",
    "  â€¢ Reasoning contradiction rate (multi-agent)\n",
    "  â€¢ User satisfaction with reasoning transparency\n",
    "\n",
    "\n",
    "CHALLENGE 5: RESUMABILITY\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "Problem: Long tasks may need to pause/resume\n",
    "Solution:\n",
    "  â€¢ State must be fully serializable\n",
    "  â€¢ Save state after each major step\n",
    "  â€¢ On resume, validate partial state\n",
    "  â€¢ Ensure idempotent reasoning steps\n",
    "\n",
    "Example:\n",
    "  # Save checkpoint\n",
    "  save_state_to_db(state)\n",
    "  \n",
    "  # Resume later\n",
    "  state = load_state_from_db(task_id)\n",
    "  validate_partial_state(state)\n",
    "  continue_reasoning(state)\n",
    "\"\"\"\n",
    "\n",
    "print(scaling_guide)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PRODUCTION DEPLOYMENT PATTERN\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "1. Design reasoning schema (types, validation)\n",
    "2. Implement reasoning loop (thought â†’ action â†’ observation)\n",
    "3. Add validation layer\n",
    "4. Add observability (logging, metrics)\n",
    "5. Load test with reasoning trace limits\n",
    "6. Deploy with monitoring\n",
    "7. Iterate based on production metrics\n",
    "\n",
    "Remember: Reasoning is infrastructure, not an afterthought.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04aaeac",
   "metadata": {},
   "source": [
    "## 10.5 Final Summary\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "Throughout this notebook, we've built a complete understanding of agent reasoning:\n",
    "\n",
    "1. **Sections 1-3:** Conceptual foundations\n",
    "   - Reasoning is externalized, structured decision-making\n",
    "   - Not chain-of-thought in prompts\n",
    "   - Iterative process: Thought â†’ Action â†’ Observation\n",
    "\n",
    "2. **Sections 4-6:** Implementation\n",
    "   - Single-agent reasoning with explicit state\n",
    "   - Validation frameworks to prevent hallucination\n",
    "   - RAG agents with evidence-based reasoning\n",
    "\n",
    "3. **Sections 7-8:** Advanced patterns\n",
    "   - Visual reasoning flows\n",
    "   - Multi-agent coordination with reasoning contracts\n",
    "\n",
    "4. **Sections 9-10:** Production readiness\n",
    "   - Common failure modes and how to avoid them\n",
    "   - Production checklist and scaling guidance\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Final Takeaway\n",
    "\n",
    "> **Agent reasoning is the structured, externalized, evidence-based, iterative process by which agents decide what to do. It must be stored in state, validated rigorously, and designed with production scaling in mind. Reasoning is not what you prompt the LLM to doâ€”it's the infrastructure you build around the LLM.**\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Practice:** Implement a simple agent using the patterns in this notebook\n",
    "2. **Validate:** Use the checklist to review your reasoning design\n",
    "3. **Scale:** Apply the production guidance when deploying\n",
    "4. **Iterate:** Monitor reasoning metrics and improve\n",
    "\n",
    "**Remember:** Good reasoning design is what separates demos from production systems.\n",
    "\n",
    "---\n",
    "\n",
    "# End of Notebook\n",
    "\n",
    "Thank you for working through **Agent Reasoning From First Principles**!\n",
    "\n",
    "For questions or to dive deeper into specific patterns, revisit the relevant sections."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
